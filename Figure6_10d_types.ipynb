{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from import_RNA import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gluta Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P12_FF_glut = sc.read_h5ad('h5ads/P22-10dWD_glut_v2.h5ad')\n",
    "P22_glut = sc.read_h5ad('h5ads/P22Sham_glut_v3.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_items, mapping_items = pairwise_map(adata_t0=P12_FF_glut, adata_t1=P22_glut,test_lab='Type',\n",
    "                                                                            train_lab='Type', \n",
    "                                                                          recomp_HVGs=True, union_hvgs=False,\n",
    "                                         t0_dict=make_dict(P12_FF_glut, 'Type'),\n",
    "                                         t1_dict=make_dict(P22_glut, 'Type'),\n",
    "                                        min_cells=100, x_lab='P22 Sham', y_lab='P12_FF Sham')\n",
    "\n",
    "test_labelsP12_FFvsP22, test_predlabelsP12_FFvsP22, test_prediction_P12_FFvsP22 = test_items\n",
    "mappingconfmatP12_FFvsP22, mappingxticksP12_FFvsP22, mappingplotP12_FFvsP22 = mapping_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_items, mapping_items = pairwise_map(adata_t0=P12_FF_glut, adata_t1=P22_glut,test_lab='Type',\n",
    "                                                                            train_lab='Type', \n",
    "                                                                          recomp_HVGs=True, union_hvgs=False,\n",
    "                                         t0_dict=make_dict(P12_FF_glut, 'Type'),\n",
    "                                         t1_dict=make_dict(P22_glut, 'Type'),\n",
    "                                        min_cells=100, x_lab='P22 Sham', y_lab='P12_FF Sham')\n",
    "\n",
    "test_labelsP12_FFvsP22, test_predlabelsP12_FFvsP22, test_prediction_P12_FFvsP22 = test_items\n",
    "mappingconfmatP12_FFvsP22, mappingxticksP12_FFvsP22, mappingplotP12_FFvsP22 = mapping_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labelsP12_FFvsP22, test_predlabelsP12_FFvsP22, test_prediction_P12_FFvsP22 = test_items\n",
    "mappingconfmatP12_FFvsP22, mappingxticksP12_FFvsP22_sub, mappingplotP12_FFvsP22 = mapping_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = make_dict(P22_glut, 'Type')\n",
    "P12_FF_glut.obs['P22 Mapping Prob'] = np.max(test_prediction_P12_FFvsP22, axis=1)\n",
    "P12_FF_glut.obs['P22 Mapping Label'] = pd.Categorical(test_predlabelsP12_FFvsP22).rename_categories(list(a.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P12_FF_glut.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type_cols = sn.color_palette('pastel').as_hex()+sn.color_palette('Set2').as_hex()+sn.color_palette('Set3').as_hex()+sn.color_palette('hls').as_hex()+sn.color_palette('husl').as_hex()\n",
    "sc.set_figure_params(dpi_save=300)\n",
    "sc.pl.umap(P12_FF_glut, color=['Type',], legend_loc='on data', \n",
    "           legend_fontsize=10, palette=type_cols, legend_fontweight='semibold', \n",
    "           frameon=False,\n",
    "           title= 'P22 1d WD: 16,654 Glutamatergic Neurons',\n",
    "           add_outline=True, save='P22-10dWD_glut')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P22_glut.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type_cols = sn.color_palette('pastel').as_hex()+sn.color_palette('Set2').as_hex()+sn.color_palette('Set3').as_hex()+sn.color_palette('hls').as_hex()+sn.color_palette('husl').as_hex()\n",
    "sc.set_figure_params(dpi_save=300)\n",
    "sc.pl.umap(P22_glut, color=['Type',], legend_loc='on data', \n",
    "           legend_fontsize=10, palette=type_cols, legend_fontweight='semibold', \n",
    "           frameon=False,\n",
    "           title= 'P22: 28,334 Glutamatergic Neurons',\n",
    "           add_outline=True, save='P22_glut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(P12_FF_glut, color=['Type','P22 Mapping Prob','P22 Mapping Label', 'Baz1a',\n",
    "                           'Trpc6', 'Igfn1'], legend_loc='on data', legend_fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P22_glut.obs['Sub'] = P22_glut.obs['Subclass'].cat.rename_categories(['L2/3', 'L4', 'L4/5IT', 'L5NP', \n",
    "                                                                      'L5PT', 'L6CT', 'L6IT', 'L6b'])\n",
    "P12_FF_glut.obs['Sub'] = P12_FF_glut.obs['Subclass'].cat.rename_categories(['L2/3', 'L4', 'L4/5IT', 'L5NP', \n",
    "                                                                      'L5PT', 'L6CT', 'L6IT', 'L6b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def freq_scatter(x, y, x_lab, y_lab, hue_, unity_lim, low_lim, save=None):\n",
    "\n",
    "    if (x.shape[0]!=y.shape[0]): \n",
    "        print('x and y are different by', np.abs(x.shape[0]-y.shape[0]), 'categories')\n",
    "    \n",
    "    if (y.shape[0]>x.shape[0]):\n",
    "        y = y[x.index]\n",
    "    else:\n",
    "        x = x[y.index]\n",
    "\n",
    "    df = pd.DataFrame(index=list(x.index.values), columns=[x_lab, y_lab],\n",
    "                      data=np.transpose(np.array([x.values, y.values])))\n",
    "\n",
    "    df[hue_] = df.index\n",
    "    sn.scatterplot(data=df, x=x_lab, y = y_lab, hue=hue_, s=50)\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1.03), loc='upper left', fontsize=14, ncol=2)\n",
    "    plt.plot(np.linspace(low_lim,unity_lim), np.linspace(low_lim,unity_lim), ls='--', \n",
    "             color='black', linewidth=0.75)\n",
    "    plt.title('Pearson R: '+str(np.round(sp.stats.pearsonr(x, y)[0], 3)))\n",
    "    plt.grid(False)\n",
    "    #plt.loglog()\n",
    "    if (save !=None):\n",
    "        plt.savefig(save, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "lims = [0.6, 0.41, 0.25, 0.35]\n",
    "low_lims = [0.2, 0.1,0,0]\n",
    "xes = []\n",
    "yes = []\n",
    "for i in ['L2/3', 'L4', 'L5', 'L6']:\n",
    "    print(i)\n",
    "    a=P22_glut[P22_glut.obs['Sub'].str.startswith(i),:]\n",
    "    b=P12_FF_glut[P12_FF_glut.obs['Sub'].str.startswith(i),:]\n",
    "    \n",
    "    xx = a.obs['Type'].value_counts(normalize=True)\n",
    "    yy = b.obs['P22 Mapping Label'].value_counts(normalize=True)\n",
    "    \n",
    "    #print(b.obs['P22 Mapping Label'].value_counts())\n",
    "    \n",
    "    if (i=='L4'):\n",
    "        freq_scatter(x=xx[0:4], y=yy[0:4],\n",
    "            x_lab='P22 Type Freqs', y_lab='P12_FF Types Mapping Freq', hue_='Types', unity_lim=lims[c], \n",
    "                 low_lim=low_lims[c])\n",
    "        oh=xx\n",
    "        my=yy\n",
    "        xes.append(xx[0:4])\n",
    "        yes.append(yy[0:4])\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        oh=xx\n",
    "        my=yy\n",
    "        freq_scatter(x=xx[xx.index.str.startswith(i)],\n",
    "            y=yy[yy.index.str.startswith(i)],\n",
    "            x_lab='P22 Type Freqs', y_lab='P12_FF Types Mapping Freq', hue_='Types', unity_lim=lims[c], \n",
    "                 low_lim=low_lims[c])\n",
    "        xes.append(xx[xx.index.str.startswith(i)])\n",
    "        yes.append(yy[yy.index.str.startswith(i)])\n",
    "        \n",
    "    plt.legend(ncol=1, bbox_to_anchor=(1,1))\n",
    "    plt.show()\n",
    "    c = c +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_scatter(x=P22_glut.obs['Type'].value_counts(normalize=True),\n",
    "            y= P12_FF_glut.obs['P22 Mapping Label'].value_counts(normalize=True),\n",
    "            x_lab='P22 Type Frequency', y_lab='10d AWD Type Frequency', hue_='Types', low_lim=0,unity_lim=0.2, \n",
    "            hue_ord = P22_glut.obs['Type'].values.categories)\n",
    "plt.savefig('figures/gluta_10dWD_freqs.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gluta Types (subclass-by-subclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "P12_FF_subs = [P12_FF_glut[P12_FF_glut.obs.Type.str.startswith('L2/3'),:],\n",
    "            P12_FF_glut[P12_FF_glut.obs.Type.str.startswith('L4'),:],\n",
    "            P12_FF_glut[P12_FF_glut.obs.Type.str.startswith('L5'),:],\n",
    "            P12_FF_glut[P12_FF_glut.obs.Type.str.startswith('L6'),:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P22_subs = [P22_glut[P22_glut.obs.Type.str.startswith('L2/3'),:],\n",
    "            P22_glut[P22_glut.obs.Type.str.startswith('L4'),:],\n",
    "            P22_glut[P22_glut.obs.Type.str.startswith('L5'),:],\n",
    "            P22_glut[P22_glut.obs.Type.str.startswith('L6'),:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Categorical(test_predlabelsP12_FFvsP22).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    num_cats_mapped = len(pd.Categorical(test_predlabelsP12_FFvsP22).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "P12_FF_subs_mapped = []\n",
    "for sub_index in range(len(P22_subs)):\n",
    "    test_items, mapping_items = pairwise_map(adata_t0=P12_FF_subs[sub_index], adata_t1=P22_subs[sub_index],test_lab='Type',\n",
    "                                                                                train_lab='Type', \n",
    "                                                                              recomp_HVGs=True, union_hvgs=False,\n",
    "                                             t0_dict=make_dict(P12_FF_subs[sub_index], 'Type'),\n",
    "                                             t1_dict=make_dict(P22_subs[sub_index], 'Type'),\n",
    "                                            min_cells=100, x_lab='P22 Sham', y_lab='P12_FF Sham')\n",
    "\n",
    "    test_labelsP12_FFvsP22, test_predlabelsP12_FFvsP22, test_prediction_P12_FFvsP22 = test_items\n",
    "    mappingconfmatP12_FFvsP22, mappingxticksP12_FFvsP22, mappingplotP12_FFvsP22 = mapping_items\n",
    "    plt.show()\n",
    "    num_cats_mapped = len(pd.Categorical(test_predlabelsP12_FFvsP22).value_counts())\n",
    "\n",
    "    P12_FF_LX = P12_FF_subs[sub_index].copy()\n",
    "    \n",
    "    \n",
    "    a = make_dict(P22_subs[sub_index], 'Type')\n",
    "    \n",
    "    \n",
    "    P12_FF_LX.obs['P22 Mapping Prob'] = np.max(test_prediction_P12_FFvsP22, axis=1)\n",
    "    \n",
    "    if (num_cats_mapped>len(a)):\n",
    "        P12_FF_LX.obs['P22 Mapping Label'] = pd.Categorical(test_predlabelsP12_FFvsP22).rename_categories(list(a.keys())+['Unassigned'])\n",
    "    else:\n",
    "        P12_FF_LX.obs['P22 Mapping Label'] = pd.Categorical(test_predlabelsP12_FFvsP22).rename_categories(list(a.keys()))\n",
    "\n",
    "    P12_FF_LX = P12_FF_LX[P12_FF_LX.obs['P22 Mapping Label']!='Unassigned'].copy()\n",
    "    P12_FF_subs_mapped.append(P12_FF_LX)\n",
    "    freq_scatter(x=P22_subs[sub_index].obs.Type.value_counts(True),\n",
    "                y= P12_FF_LX.obs['P22 Mapping Label'].value_counts(True),\n",
    "                x_lab='P22 Type Freqs', y_lab='P12_FF Types Mapping Freq', hue_='Types', low_lim=0,unity_lim=0.55, )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P22_ctrl = P22_subs[0].concatenate(P22_subs[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P22_10d  = P12_FF_subs_mapped[0].concatenate(P12_FF_subs_mapped[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "freq_scatter(x=P22_ctrl.obs.Type.value_counts(True),\n",
    "                y= P22_10d.obs['P22 Mapping Label'].value_counts(True),\n",
    "                x_lab='P22 Type Freqs', y_lab='P22 10d-WD Types Mapping Freq', hue_='Types', low_lim=0,unity_lim=0.2, )\n",
    "plt.savefig('figures/10d_typefreq_glut.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_barplot(adata1, adata2):\n",
    "    \n",
    "    freq1 = adata1.obs['P22 Mapping Label'].value_counts(normalize=True)\n",
    "    freq2 =  adata2.obs['Type'].value_counts(normalize=True)\n",
    "\n",
    "    freq_df = pd.DataFrame(freq1)\n",
    "    freq_df['Type'] = freq_df.index\n",
    "    freq_df['Freq'] = freq_df['P22 Mapping Label']\n",
    "\n",
    "    del freq_df['P22 Mapping Label']\n",
    "\n",
    "    freq_df['Age'] = len(freq1)*['10d-WD']\n",
    "\n",
    "    freq_df22 = pd.DataFrame(freq2)\n",
    "    freq_df22['Freq'] = freq_df22['Type']\n",
    "    freq_df22['Type'] = freq_df22.index\n",
    "\n",
    "    freq_df22['Age'] = len(freq2)*['P22']\n",
    "\n",
    "    df = pd.concat([freq_df, freq_df22])\n",
    "\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(1,1,figsize=(6.25,1.25))\n",
    "    pivot_df = df.pivot(index='Age', columns='Type', values='Freq')\n",
    "\n",
    "    # Plot\n",
    "    pivot_df.loc[['P22','10d-WD']].plot(kind='barh', stacked=True,width=0.8, ax=axs, color=sn.color_palette('Set2').as_hex(),)\n",
    "\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.grid(False)\n",
    "    plt.legend(bbox_to_anchor=(1,1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P12_FF_subs_mapped[0].obs['P22 Mapping Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.528561 - 0.484319"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P22_subs[0].obs['Type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.180596 - 0.155567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = P22_ctrl.obs['Type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = P22_10d.obs['P22 Mapping Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[a.index]/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_barplot(P12_FF_subs_mapped[0], P22_subs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_barplot(P12_FF_subs_mapped[1], P22_subs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_barplot(P12_FF_subs_mapped[2], P22_subs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_barplot(P12_FF_subs_mapped[3], P22_subs[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save mapped objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P12_FF_subs_mapped[0].write_h5ad('h5ads_cmprsd/P12_FF_L23_mappedP22.h5ad')\n",
    "\n",
    "P22_10d.write_h5ad('h5ads_cmprsd/P12_FF_glut_mappedP22.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GABA Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P12_FF_gaba = sc.read_h5ad('h5ads/P22-10dWD_gaba_v2.h5ad')\n",
    "P22_gaba = sc.read_h5ad('h5ads/P22Sham_gaba_v3.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Had to un-do the change to plotConfusionMatrix() from sub-by-sub analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#code\n",
    "#import\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "from harmony import harmonize\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.utils import shuffle\n",
    "from anndata import AnnData\n",
    "from sklearn.cluster import KMeans\n",
    "from typing import Union, Optional, Tuple, Collection, Sequence, Iterable\n",
    "from scipy.stats import hypergeom\n",
    "import sklearn.preprocessing\n",
    "import seaborn as sn\n",
    "from random import sample\n",
    "import pickle\n",
    "#from matplotlib_venn import venn3, venn3_circles\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "\n",
    "\n",
    "from matplotlib import gridspec\n",
    "from sklearn.metrics import confusion_matrix, adjusted_rand_score, roc_curve, auc, classification_report, f1_score, cohen_kappa_score\n",
    "import plotly.graph_objects as go\n",
    "from itertools import cycle, islice\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import scanpy as sc\n",
    "sc.settings.verbosity = 3             # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.set_figure_params(dpi=100, dpi_save=200)\n",
    "\n",
    "\n",
    "import scrublet as scr\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import gridspec\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "sc.settings.verbosity = 0           # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_header()\n",
    "sc.set_figure_params(dpi=75, dpi_save=200)\n",
    "\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "def test_func():\n",
    "    print('test')\n",
    "    \n",
    "def test2():\n",
    "    print('test2')\n",
    "def rem_fem(adata):\n",
    "    for j in list(adata.obs.Type_nn_dists.values.categories):\n",
    "        if ('Fem' in j):\n",
    "            adata = adata[adata.obs['Type_nn_dists']!=j,:]\n",
    "            adata = adata[adata.obs['Type_leiden']!=j,:]\n",
    "            adata = adata[adata.obs['Type']!=j,:]\n",
    "    return adata\n",
    "def pipeline_short(adata, batch_correct, batch_ID):\n",
    "                   \n",
    "    if sp.sparse.issparse(adata.X):\n",
    "        if np.any(adata.X.A<0):\n",
    "            raise Exception(\"Matrix contains negative values\")\n",
    "    else: \n",
    "        if np.any(adata.X<0):\n",
    "            raise Exception(\"Matrix contains negative values\")\n",
    "\n",
    "    \n",
    "    sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, batch_key=batch_ID) #HVGs\n",
    "    adata.raw = adata\n",
    "    sc.pp.scale(adata, max_value=10) #scale\n",
    "    sc.tl.pca(adata, svd_solver='arpack') #run PCA\n",
    "    \n",
    "    if (batch_correct):\n",
    "        Z = harmonize(adata.obsm['X_pca'], adata.obs, batch_key = batch_ID)\n",
    "        adata.obsm['X_harmony'] = Z\n",
    "        sc.pp.neighbors(adata, n_neighbors=15, use_rep='X_harmony', n_pcs=40)\n",
    "        sc.tl.leiden(adata)\n",
    "        sc.tl.umap(adata)\n",
    "\n",
    "    else:\n",
    "        sc.pp.neighbors(adata, n_neighbors=15, n_pcs=40)\n",
    "        sc.tl.leiden(adata)\n",
    "        sc.tl.umap(adata)\n",
    "        \n",
    "def pre_process(adata, batch_ID):\n",
    "    \n",
    "    if sp.sparse.issparse(adata.X):\n",
    "        if np.any(adata.X.A<0):\n",
    "            raise Exception(\"Matrix contains negative values\")\n",
    "    else: \n",
    "        if np.any(adata.X<0):\n",
    "            raise Exception(\"Matrix contains negative values\")\n",
    "    \n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "    sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5, batch_key=batch_ID) #HVGs\n",
    "    adata.raw = adata\n",
    "    sc.pp.scale(adata, max_value=10) #scale\n",
    "    sc.tl.pca(adata, svd_solver='arpack') #run PCA\n",
    "    \n",
    "\n",
    "def pipeline(adata, \n",
    "             batch_correct: Optional[bool] = None,\n",
    "             batch_ID: Optional[str] = None):\n",
    "    \n",
    "    if (batch_correct):\n",
    "        Z = harmonize(adata.obsm['X_pca'], adata.obs, batch_key = batch_ID)\n",
    "        adata.obsm['X_harmony'] = Z\n",
    "        sc.pp.neighbors(adata, n_neighbors=15, use_rep='X_harmony', n_pcs=40)\n",
    "        sc.tl.leiden(adata)\n",
    "        sc.tl.umap(adata)\n",
    "\n",
    "    else:\n",
    "        sc.pp.neighbors(adata, n_neighbors=15, n_pcs=40)\n",
    "        sc.tl.leiden(adata)\n",
    "        sc.tl.umap(adata)\n",
    "\n",
    "def clust_obs_plot(adata, obs_id, obs_id_split):\n",
    "\n",
    "    obs_quants = []\n",
    "    for i in adata.obs[obs_id_split].values.categories:\n",
    "    #for i in dr_corr.obs['Atlas Label'].values.categories:\n",
    "        obs_quants.append(np.mean(adata[adata.obs[obs_id_split]==i].obs[obs_id].values))\n",
    "        \n",
    "    x, y = adata.obs[obs_id_split].values.categories, obs_quants\n",
    "    ser = pd.Series(y,x).sort_values(ascending=False)\n",
    "    \n",
    "    x,y = ser.index, ser.values\n",
    "    \n",
    "    plt.figure(figsize=(15,4))\n",
    "    plt.bar(x,y)\n",
    "    plt.axhline(np.median(adata.obs[obs_id]), color='r')\n",
    "    plt.ylabel(obs_id)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "def DE(adata, obs_id, obs_id_test, ref, pts_thresh, lf_thresh):\n",
    "\n",
    "    sc.tl.rank_genes_groups(adata, groupby=obs_id, groups=[obs_id_test], \n",
    "                                reference=ref, method='t-test', pts=True, use_raw=True)\n",
    "\n",
    "    lfcs = adata.uns['rank_genes_groups']['logfoldchanges'].astype([(obs_id_test, '<f8')]).view('<f8') \n",
    "\n",
    "    l231_genes = adata.uns['rank_genes_groups']['pts']\n",
    "\n",
    "    lfcs = []\n",
    "    p_adj = []\n",
    "    names = list(adata.uns['rank_genes_groups']['names'].astype([(obs_id_test, '<U50')]).view('<U50'))\n",
    "    logfoldchanges = adata.uns['rank_genes_groups']['logfoldchanges'].astype([(obs_id_test, '<f8')]).view('<f8')\n",
    "    pvals_adj = adata.uns['rank_genes_groups']['pvals_adj'].astype([(obs_id_test, '<f8')]).view('<f8')\n",
    "\n",
    "    for i in l231_genes.index:\n",
    "        lfcs.append(logfoldchanges[names.index(i)])\n",
    "        p_adj.append(pvals_adj[names.index(i)])\n",
    "\n",
    "    l231_genes['LF'] = lfcs\n",
    "    l231_genes['p_adj'] = p_adj\n",
    "    \n",
    "    #plt.hist(l231_genes[obs_id_test].values)\n",
    "\n",
    "    l231_genes = l231_genes[l231_genes[obs_id_test]>pts_thresh]\n",
    "    \n",
    "    sort_LF = l231_genes.sort_values('LF', ascending=False)\n",
    "    \n",
    "    a = np.where(sort_LF[sort_LF['LF']>0.6]['p_adj'].values<0.05)[0].shape[0]\n",
    "    b = sort_LF[sort_LF['LF']>0.6].shape[0]\n",
    "    if(a == b):\n",
    "        print('cutoffs are good at 1.5 FC level')\n",
    "    else:\n",
    "        print(a,b)\n",
    "        \n",
    "    return sort_LF[sort_LF['LF']>lf_thresh]\n",
    "        \n",
    "def clust_obs(adata, obs_id, obs_id_split):\n",
    "\n",
    "    obs_quants = []\n",
    "    for i in adata.obs[obs_id_split].values.categories:\n",
    "    #for i in dr_corr.obs['Atlas Label'].values.categories:\n",
    "        obs_quants.append(np.mean(adata[adata.obs[obs_id_split]==i].obs[obs_id].values))\n",
    "        \n",
    "    x, y = adata.obs[obs_id_split].values.categories, obs_quants\n",
    "    ser = pd.Series(y,x).sort_values(ascending=False)\n",
    "    return ser.index, ser.values\n",
    "\n",
    "def res_tune(adata, def_labels):\n",
    "    \n",
    "    adata_ari = []\n",
    "    adata_num_clusts = []\n",
    "    for res in np.arange(1,2.1, 0.1):\n",
    "        sc.tl.leiden(adata, resolution=res)\n",
    "\n",
    "        adata_num_clusts.append(len(adata.obs.leiden.values.categories))\n",
    "        adata_ari.append(adjusted_rand_score(def_labels, list(adata.obs.leiden.values)))\n",
    "        \n",
    "    return adata_num_clusts, adata_ari\n",
    "\n",
    "from math import log, e\n",
    "def entropy2(labels, base=None):\n",
    "  \"\"\" Computes entropy of label distribution. \"\"\"\n",
    "\n",
    "  n_labels = len(labels)\n",
    "\n",
    "  if n_labels <= 1:\n",
    "    return 0\n",
    "\n",
    "  value,counts = np.unique(labels, return_counts=True)\n",
    "  probs = counts / n_labels\n",
    "  n_classes = np.count_nonzero(probs)\n",
    "\n",
    "  if n_classes <= 1:\n",
    "    return 0\n",
    "\n",
    "  ent = 0.\n",
    "\n",
    "  # Compute entropy\n",
    "  base = e if base is None else base\n",
    "  for i in probs:\n",
    "    ent -= i * log(i, base)\n",
    "\n",
    "  return ent\n",
    "\n",
    "def check_clust(adata, clus, ref_age):\n",
    "    sc.pl.umap(adata[adata.obs.leiden==clus], color=[ref_age+'-2022 Mapping Prob', ref_age+'-2022 Mapping Label'])\n",
    "    print(adata[adata.obs.leiden==clus].shape, 'mean prob', np.mean(adata[adata.obs.leiden==clus].obs[ref_age+'-2022 Mapping Prob']))\n",
    "    ser = adata[adata.obs.leiden==clus].obs['Sample'].value_counts()\n",
    "    plt.bar(ser.index, ser.values,)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    ser = adata[adata.obs.leiden==clus].obs[ref_age+'-2022 Mapping Label'].value_counts()\n",
    "    plt.bar(ser.index, ser.values,)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    \n",
    "def maj_vote_annot(adata, clust_id, putative_annot, final_annot, vlmcendo=False):\n",
    "    clust_list = []\n",
    "    for i in adata.obs[clust_id].values.categories:\n",
    "        clust = adata[adata.obs[clust_id]==i,:]\n",
    "        clust_df = clust.obs[putative_annot].value_counts()\n",
    "        if (clust_df.index[0]=='Unassigned'):\n",
    "            biggest_cat = clust_df.index[1]\n",
    "        else: biggest_cat = clust_df.index[0]\n",
    "        if (vlmcendo):\n",
    "            if (biggest_cat in ('VLMC', 'Endo')):\n",
    "                clust.obs[putative_annot+'_maj'] = ['VLMC+Endo']*clust.shape[0]\n",
    "                clust_list.append(clust)\n",
    "            else:\n",
    "                clust.obs[putative_annot+'_maj'] = [biggest_cat]*clust.shape[0]\n",
    "                clust_list.append(clust)\n",
    "        else:\n",
    "            clust.obs[putative_annot+'_maj'] = [biggest_cat]*clust.shape[0]\n",
    "            clust_list.append(clust)\n",
    "\n",
    "    adata_annot = clust_list[0].concatenate(clust_list[1:], index_unique=None)\n",
    "    adata_annot.obs[final_annot] = adata_annot.obs[putative_annot+'_maj']\n",
    "    a = sc.pl.dotplot(adata_annot, 'Mdga1', 'leiden',) #to fix categories\n",
    "    return adata_annot\n",
    "\n",
    "def clus_sample_bars(adata, a_, b_, samp_id, clus_id, size=(13,9.5)):\n",
    "    adata_ser = adata.obs[samp_id].value_counts(normalize=True)\n",
    "    plt.bar(adata_ser.index, adata_ser.values)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title('Overall Dataset')\n",
    "    plt.show()\n",
    "    a,b = 0 ,0 \n",
    "    fig, axs = plt.subplots(a_,b_, figsize=size)\n",
    "\n",
    "    for i in adata.obs[clus_id].values.categories:\n",
    "        clus = adata[adata.obs[clus_id]==i,:]\n",
    "        clus_ser = clus.obs[samp_id].value_counts(normalize=True)\n",
    "        axs[a,b].bar(clus_ser.index, clus_ser.values)\n",
    "        axs[a,b].set_title(i+' ('+str(clus.shape[0])+' cells)')\n",
    "        axs[a,b].set_ylabel('Fraction')\n",
    "        axs[a,b].set_xticklabels(clus_ser.index, rotation=90)\n",
    "        b = b + 1\n",
    "        if (b>=b_):\n",
    "            b = 0\n",
    "            a = a + 1\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "def euclidean_distance(vector1, vectors_list):\n",
    "    # Ensure that the input vectors are numpy arrays\n",
    "    vector1 = np.array(vector1)\n",
    "    vectors_list = [np.array(vector) for vector in vectors_list]\n",
    "    \n",
    "    # Calculate the Euclidean distance between the input vector and each vector in the list\n",
    "    distances = [np.linalg.norm(vector1 - vector) for vector in vectors_list]\n",
    "    return distances\n",
    "\n",
    "def nn_voting(adata, type_old, type_new, delta_thresh):\n",
    "    adata.obs['idx'] = np.arange(adata.shape[0])\n",
    "\n",
    "#     #re-make graph using UMAP space for voting below\n",
    "#     sc.pp.neighbors(adata, n_neighbors=15, use_rep='X_umap')\n",
    "#     sc.tl.umap(adata)\n",
    "\n",
    "    adata.obs[type_new] = adata.obs[type_old]\n",
    "    adata_un_idx = adata[adata.obs[type_old]=='Unassigned',:].obs.idx.values #indices of unassigned cells\n",
    "    neigh_matx = adata.obsp['distances'].A #each row's nonzero entries tells neighbors\n",
    "    adata_iGBs = list(adata.obs[type_old].values) #all the step1 assignments\n",
    "    n_neighbs = adata.uns['neighbors']['params']['n_neighbors']\n",
    "    print(adata.uns['neighbors']['params'])\n",
    "    print(' ')\n",
    "    \n",
    "    print(\"Pre-voting unassigned: \", adata_iGBs.count('Unassigned'),\n",
    "          adata_iGBs.count('Unassigned')/adata.shape[0])\n",
    "    \n",
    "    \n",
    "    delta = 1 #init delta\n",
    "    while (delta>delta_thresh):    \n",
    "        un_frac1 = adata_iGBs.count('Unassigned')/adata.shape[0] #frac of unassigned cells before voting\n",
    "\n",
    "        #loop thru each cell\n",
    "        for i in adata_un_idx:\n",
    "\n",
    "            #so that it only loops thru still-unassigned cells after first pass\n",
    "            if (adata.obs[type_new][i]=='Unassigned'):\n",
    "                neighbs_idx = np.where(neigh_matx[i,:]>0)[0] #cell i's neighbors\n",
    "                neighbs_iGBs = adata[neighbs_idx].obs[type_new] #the neighbors' iGBs\n",
    "\n",
    "#                 #if there's a type in the neighbors that is majority, assign it\n",
    "#                 if (neighbs_iGBs.value_counts()[0] > n_neighbs/2):\n",
    "#                     adata_iGBs[i] = neighbs_iGBs.value_counts().index[0]\n",
    "                \n",
    "                #no need to be majority, just be biggest one\n",
    "                adata_iGBs[i] = neighbs_iGBs.value_counts().index[0]\n",
    "                #update the IDs to help assignment of next cell\n",
    "                adata.obs[type_new] =  pd.Categorical(adata_iGBs)\n",
    "\n",
    "        un_frac2 = adata_iGBs.count('Unassigned')/adata.shape[0] #frac of unassigned cells after voting\n",
    "\n",
    "        delta = (un_frac1-un_frac2)/un_frac1   #stop when this changes by less than 1%\n",
    "        print(delta, un_frac2)\n",
    "\n",
    "    print(\"Post-voting unassigned: \", adata_iGBs.count('Unassigned'),\n",
    "          adata_iGBs.count('Unassigned')/adata.shape[0])\n",
    "    \n",
    "    return adata\n",
    "\n",
    "\n",
    "def make_hmap(adata,thres, y_obs='Type', x_obs='leiden', ):\n",
    "    crosstab_data = pd.crosstab(adata.obs[y_obs], adata.obs[x_obs], \n",
    "                           normalize='index')\n",
    "    # For rows\n",
    "    row_order = np.argsort(-crosstab_data.values.max(axis=1))\n",
    "\n",
    "    # For columns\n",
    "    column_order = np.argsort(-crosstab_data.values.max(axis=0))\n",
    "\n",
    "    reordered_rows = crosstab_data.index[row_order]\n",
    "    reordered_crosstab_rows = crosstab_data.iloc[row_order]\n",
    "\n",
    "    # For columns\n",
    "    reordered_columns = crosstab_data.columns[column_order]\n",
    "    reordered_crosstab = reordered_crosstab_rows[reordered_columns]\n",
    "    #return reordered_crosstab\n",
    "    \n",
    "    \n",
    "    from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "    \n",
    "\n",
    "    labels_true = adata.obs[y_obs]\n",
    "    labels_pred = adata.obs[x_obs]\n",
    "\n",
    "    # Compute the Adjusted Rand Index\n",
    "    ari = adjusted_rand_score(labels_true, labels_pred)\n",
    "    \n",
    "    return [reordered_crosstab.applymap(lambda value: value if value > thres else np.round(value, 2)),\n",
    "           ari]\n",
    "def freq_scatter(x, y, x_lab, y_lab, hue_, unity_lim, low_lim):\n",
    "\n",
    "    if (x.shape[0]!=y.shape[0]): \n",
    "        print('x and y are different by', np.abs(x.shape[0]-y.shape[0]), 'categories')\n",
    "    \n",
    "    if (y.shape[0]>x.shape[0]):\n",
    "        y = y[x.index]\n",
    "    else:\n",
    "        x = x[y.index]\n",
    "\n",
    "    df = pd.DataFrame(index=list(x.index.values), columns=[x_lab, y_lab],\n",
    "                      data=np.transpose(np.array([x.values, y.values])))\n",
    "\n",
    "    df[hue_] = df.index\n",
    "    sn.scatterplot(data=df, x=x_lab, y = y_lab, hue=hue_, s=50)\n",
    "    plt.legend(bbox_to_anchor=(1.01, 1.03), loc='upper left', fontsize=14, ncol=2)\n",
    "    plt.plot(np.linspace(low_lim,unity_lim), np.linspace(low_lim,unity_lim), ls='--', \n",
    "             color='black', linewidth=0.75)\n",
    "    plt.title('Pearson R: '+str(np.round(sp.stats.pearsonr(x, y)[0], 3)))\n",
    "    plt.grid(False)\n",
    "    #plt.loglog()\n",
    "    \n",
    "\n",
    "\n",
    "from anndata import AnnData\n",
    "from typing import Union, Optional, Tuple, Collection, Sequence, Iterable\n",
    "\n",
    "def module_score(adata:AnnData, genes_use: list, score_name: Optional[str] = None, verbose: bool = True):\n",
    "    \n",
    "    \"\"\"\\\n",
    "    Compute module scores for all cells in adata as described in methods of RGC-dev paper.\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adata\n",
    "        The (annotated) data matrix of shape `n_obs` Ã— `n_vars`.\n",
    "        Rows correspond to cells and columns to genes.\n",
    "    genes_use\n",
    "        list of genes in module of interest\n",
    "    score_name\n",
    "        Name endowed to the module score to be computed\n",
    "        e.g. \"Mod1\"\n",
    "    verbose\n",
    "        Inform user of fraction of module genes that are in adata\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    adata with a new .obs called score_name\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if (score_name==None):\n",
    "        score_name = str(input(\"Provide a name for this score (no spaces): \"))\n",
    "        \n",
    "    genes_use0 = genes_use\n",
    "    genes_use = list(set(genes_use).intersection(adata.var_names))#genes that are both in module and `adata`\n",
    "    \n",
    "     \n",
    "    if (len(genes_use) == 0):\n",
    "        raise ValueError(\"Error : Must provide a list of genes that are present in the data\")\n",
    "        \n",
    "    \n",
    "    if (verbose):\n",
    "        if(len(genes_use0) > len(genes_use)):\n",
    "            n = len(genes_use0) - len(genes_use)\n",
    "            print(score_name,\": Note that\", n, \"of the\", len(genes_use0), \"genes in your module do not exist in the data set.\" )\n",
    "        else:\n",
    "            print(score_name,\": Note that all of the\", len(genes_use), \"genes in your module are in the data set.\" )\n",
    "    \n",
    "    \n",
    "    \n",
    "    adata_score = adata.copy()\n",
    "    adata_score = adata[:,genes_use]\n",
    "    \n",
    "    counts_modgenes = adata_score.X.toarray() #all cells, module genes\n",
    "    counts_all = adata.X.toarray() #all cells, all genes\n",
    "    #scores = np.mean(counts_modgenes, axis=1) - np.mean(counts_all, axis=1) #(row means of counts_modgenes ) - (row means of counts_all)\n",
    "    scores = np.mean(counts_modgenes, axis=1) #(row means of counts_modgenes )\n",
    "\n",
    "    adata.obs[score_name] = scores\n",
    "    \n",
    "    return genes_use    \n",
    "    \n",
    "\n",
    "def clean_subclasses(adata, rep):\n",
    "    #define avg PC position of each type. Gotta use a type with no \"Unassigned\" group\n",
    "    typ_mean_dict = {}\n",
    "    for i in adata.obs['Subclass'].values.categories:\n",
    "        typ_mean_dict[i] = np.mean(adata[adata.obs['Subclass']==i,:].obsm[rep][:,0:40], axis=0)\n",
    "\n",
    "    #assign based on proximity to avg type\n",
    "    dists_list = []\n",
    "    dict_keys = list(typ_mean_dict.keys())\n",
    "    for i in range(adata.shape[0]):\n",
    "        typ_ = adata.obs['Subclass'][i]\n",
    "        dists = euclidean_distance(adata.obsm[rep][i,0:40], list(typ_mean_dict.values()))\n",
    "\n",
    "        #dist = dists[dict_keys.index(typ_)]\n",
    "        typ = dict_keys[np.argmin(dists)]\n",
    "        #types.append(typ)\n",
    "        if (typ!=typ_):\n",
    "            dists_list.append(100)\n",
    "        else: dists_list.append(0)\n",
    "\n",
    "    adata.obs['Dist to Subclass'] = dists_list\n",
    "    \n",
    "def make_dict(adata, obs_id):\n",
    "\n",
    "    adata_dict = {}\n",
    "    for num,i in enumerate(adata.obs[obs_id].values.categories):\n",
    "        adata_dict[i] = num\n",
    "        \n",
    "    #adata_dict['Unassigned'] = num + 1\n",
    "    \n",
    "    return adata_dict\n",
    "    \n",
    "\n",
    "def plotConfusionMatrix(\n",
    "    ytrue,\n",
    "    ypred,\n",
    "    type,\n",
    "    xaxislabel,\n",
    "    yaxislabel,\n",
    "    title,\n",
    "    train_dict,\n",
    "    test_dict=None,\n",
    "    re_order=None,\n",
    "    re_order_cols = None,\n",
    "    re_index = None,\n",
    "    re_order_rows = None,\n",
    "    save_as=None,):\n",
    "    \n",
    "    #very bad\n",
    "    numbertrainclasses = len(set(ypred))\n",
    "    numbertestclasses = len(set(ytrue))\n",
    "    \n",
    "    #cfm is 11x11 b/c 11 is = y_true U y_pred\n",
    "    confusionmatrix = confusion_matrix(y_true = ytrue, y_pred = ypred)\n",
    "        \n",
    "    #only need this when mapping b/c if validaiton, all classes will be used and cfm will be constructed properly\n",
    "    if type == 'mapping':\n",
    "        rows = np.where(np.sum(confusionmatrix, axis=1)>0)[0]\n",
    "        cols = np.where(np.sum(confusionmatrix, axis=0)>0)[0]\n",
    "        \n",
    "        cfm = confusionmatrix[rows,:][:,cols]\n",
    "        \n",
    "        #show all columns, even ones with no mapping\n",
    "        \n",
    "        #this was changed 10/12/2023 to address unassigned issue\n",
    "        cfm_z = np.zeros((len(test_dict),len(train_dict)))\n",
    "        #cfm_z = np.zeros((len(rows),len(cols)))\n",
    "\n",
    "        cfm_z[:, np.array(pd.Categorical(ypred).categories, dtype='int')]=cfm \n",
    "        confusionmatrix = cfm_z\n",
    "        \n",
    "        #always keep only as many as rows as num of test classes\n",
    "        #but, b/c of python's 0 indexing, if the number of training classes is in the \n",
    "        #y_pred list, then that means there was an unassigned\n",
    "#       if numbertrainclasses in ypred:\n",
    "#         confusionmatrix = confusionmatrix[0:numbertestclasses,0:numbertrainclasses+1]#for Unassigned\n",
    "#       else:\n",
    "#         confusionmatrix = confusionmatrix[0:numbertestclasses,0:numbertrainclasses]\n",
    "    \n",
    "        confmatpercent = confusionmatrix/np.sum(confusionmatrix, axis=1).reshape(-1,1)\n",
    "\n",
    "        conf_df = pd.DataFrame(confmatpercent)\n",
    "        conf_df.index = list(test_dict.keys())\n",
    "\n",
    "        #name columns of conf mat\n",
    "        if(len(conf_df.columns)>len(train_dict)):\n",
    "            conf_df.columns = list(train_dict.keys())+['Unassigned']\n",
    "        else:\n",
    "            conf_df.columns = list(train_dict.keys())\n",
    "\n",
    "\n",
    "        if (re_order):\n",
    "            conf_df = conf_df[re_order_cols]\n",
    "        if (re_index):\n",
    "            conf_df = conf_df.reindex(re_order_rows)\n",
    "\n",
    "        diagcm = conf_df.to_numpy()\n",
    "    \n",
    "    \n",
    "        xticksactual = list(conf_df.columns)\n",
    "        \n",
    "        #print(conf_df)\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        confmatpercent = np.zeros(confusionmatrix.shape)\n",
    "        for i in range(confusionmatrix.shape[0]):\n",
    "            if np.sum(confusionmatrix[i,:]) != 0:\n",
    "                confmatpercent[i,:] = confusionmatrix[i,:]/np.sum(confusionmatrix[i,:])\n",
    "            else:\n",
    "                confmatpercent[i,:] = confusionmatrix[i,:]\n",
    "            diagcm = confmatpercent\n",
    "            xticks = np.linspace(0, confmatpercent.shape[1]-1, confmatpercent.shape[1], dtype = int)\n",
    "        xticksactual = []\n",
    "        for i in xticks:\n",
    "            if i != numbertrainclasses:\n",
    "                xticksactual.append(list(train_dict.keys())[i])\n",
    "            else:\n",
    "                xticksactual.append('Unassigned')\n",
    "        \n",
    "    dot_max = np.max(diagcm.flatten())\n",
    "    dot_min = 0\n",
    "    if dot_min != 0 or dot_max != 1:\n",
    "        frac = np.clip(diagcm, dot_min, dot_max)\n",
    "        old_range = dot_max - dot_min\n",
    "        frac = (frac - dot_min) / old_range\n",
    "    else:\n",
    "        frac = diagcm\n",
    "    xvalues = []\n",
    "    yvalues = []\n",
    "    sizes = []\n",
    "    for i in range(diagcm.shape[0]):\n",
    "        for j in range(diagcm.shape[1]):\n",
    "            xvalues.append(j)\n",
    "            yvalues.append(i)\n",
    "            sizes.append((frac[i,j]*35)**1.5)\n",
    "    size_legend_width = 0.5\n",
    "    height = diagcm.shape[0] * 0.3 + 1\n",
    "    height = max([1.5, height])\n",
    "    heatmap_width = diagcm.shape[1] * 0.35\n",
    "    width = (\n",
    "        heatmap_width\n",
    "        + size_legend_width\n",
    "        )\n",
    "    fig = plt.figure(figsize=(width, height))\n",
    "    axs = gridspec.GridSpec(\n",
    "        nrows=2,\n",
    "        ncols=2,\n",
    "        wspace=0.02,\n",
    "        hspace=0.04,\n",
    "        width_ratios=[\n",
    "                    heatmap_width,\n",
    "                    size_legend_width\n",
    "                    ],\n",
    "        height_ratios = [0.5, 10]\n",
    "        )\n",
    "    dot_ax = fig.add_subplot(axs[1, 0])\n",
    "    dot_ax.scatter(xvalues,yvalues, s = sizes, c = 'blue', norm=None, edgecolor='none')\n",
    "    y_ticks = range(diagcm.shape[0])\n",
    "    dot_ax.set_yticks(y_ticks)\n",
    "    if type == 'validation':\n",
    "        dot_ax.set_yticklabels(list(train_dict.keys()))\n",
    "    elif type == 'mapping':\n",
    "      #dot_ax.set_yticklabels(list(test_dict.keys()))\n",
    "        dot_ax.set_yticklabels(list(conf_df.index))\n",
    "    x_ticks = range(diagcm.shape[1])\n",
    "    dot_ax.set_xticks(x_ticks)\n",
    "    dot_ax.set_xticklabels(xticksactual, rotation=90)\n",
    "    dot_ax.tick_params(axis='both', labelsize='small')\n",
    "    dot_ax.grid(True, linewidth = 0.2)\n",
    "    dot_ax.set_axisbelow(True)\n",
    "    dot_ax.set_xlim(-0.5, diagcm.shape[1] + 0.5)\n",
    "    ymin, ymax = dot_ax.get_ylim()\n",
    "    dot_ax.set_ylim(ymax + 0.5, ymin - 0.5)\n",
    "    dot_ax.set_xlim(-1, diagcm.shape[1])\n",
    "    dot_ax.set_xlabel(xaxislabel)\n",
    "    dot_ax.set_ylabel(yaxislabel)\n",
    "    dot_ax.set_title(title)\n",
    "    size_legend_height = min(1.75, height)\n",
    "    wspace = 10.5 / width\n",
    "    axs3 = gridspec.GridSpecFromSubplotSpec(\n",
    "        2,\n",
    "        1,\n",
    "        subplot_spec=axs[1, 1],\n",
    "        wspace=wspace,\n",
    "        height_ratios=[\n",
    "                    size_legend_height / height,\n",
    "                    (height - size_legend_height) / height\n",
    "                    ]\n",
    "        )\n",
    "    diff = dot_max - dot_min\n",
    "    if 0.3 < diff <= 0.6:\n",
    "        step = 0.1\n",
    "    elif diff <= 0.3:\n",
    "        step = 0.05\n",
    "    else:\n",
    "        step = 0.2\n",
    "    fracs_legends = np.arange(dot_max, dot_min, step * -1)[::-1]\n",
    "    if dot_min != 0 or dot_max != 1:\n",
    "        fracs_values = (fracs_legends - dot_min) / old_range\n",
    "    else:\n",
    "        fracs_values = fracs_legends\n",
    "    size = (fracs_values * 35) ** 1.5\n",
    "    size_legend = fig.add_subplot(axs3[0])\n",
    "    size_legend.scatter(np.repeat(0, len(size)), range(len(size)), s=size, c = 'blue')\n",
    "    size_legend.set_yticks(range(len(size)))\n",
    "    labels = [\"{:.0%}\".format(x) for x in fracs_legends]\n",
    "    if dot_max < 1:\n",
    "        labels[-1] = \">\" + labels[-1]\n",
    "    size_legend.set_yticklabels(labels)\n",
    "    size_legend.set_yticklabels([\"{:.0%}\".format(x) for x in fracs_legends])\n",
    "    size_legend.tick_params(axis='y', left=False, labelleft=False, labelright=True)\n",
    "    size_legend.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "    size_legend.spines['right'].set_visible(False)\n",
    "    size_legend.spines['top'].set_visible(False)\n",
    "    size_legend.spines['left'].set_visible(False)\n",
    "    size_legend.spines['bottom'].set_visible(False)\n",
    "    size_legend.grid(False)\n",
    "    ymin, ymax = size_legend.get_ylim()\n",
    "    size_legend.set_ylim(ymin, ymax + 0.5)\n",
    "    \n",
    "    if (save_as is not None):\n",
    "        fig.savefig(save_as, bbox_inches = 'tight')\n",
    "\n",
    "    return diagcm, xticksactual, axs\n",
    "\n",
    "\n",
    "\n",
    "#This helper method plots validation plots in sequential order (i.e. first plot is for first batch, second plot is for second batch, etc.)\n",
    "def plot_validation_plots(validation_label_train_70, valid_predlabels_train_70, train_dict, save_as=None):\n",
    "    \n",
    "    ARI = adjusted_rand_score(labels_true = validation_label_train_70, \n",
    "                              labels_pred = valid_predlabels_train_70)\n",
    "    \n",
    "    \n",
    "    c = 0\n",
    "    for i in range(validation_label_train_70.shape[0]):\n",
    "        if (validation_label_train_70[i]!=valid_predlabels_train_70[i]):\n",
    "            c = c +1\n",
    "    acc = (1 - c/len(validation_label_train_70))*100\n",
    "    \n",
    "           \n",
    "    validationconfmat, validationxticks, validationplot = plotConfusionMatrix(\n",
    "    ytrue = validation_label_train_70,\n",
    "    ypred = valid_predlabels_train_70,\n",
    "    train_dict=train_dict,\n",
    "    type = 'validation',\n",
    "    save_as = save_as,\n",
    "    title = 'ARI = {:.3f}, Accuracy = {:.3f}'.format(ARI, acc),\n",
    "    xaxislabel = 'Predicted',\n",
    "    yaxislabel = 'True'\n",
    "    )\n",
    "\n",
    "def plot_mapping(test_labels, test_predlabels, test_dict, train_dict, \n",
    "                 xaxislabel, yaxislabel,\n",
    "                re_order=None,\n",
    "    re_order_cols = None,\n",
    "                 re_index = None,\n",
    "    re_order_rows = None, save_as=None):\n",
    "    \n",
    "    ARI = adjusted_rand_score(labels_true = test_labels, \n",
    "                              labels_pred = test_predlabels)\n",
    "    NCE = calculateNCE(labels_true = test_labels, labels_pred = test_predlabels)\n",
    "    \n",
    " \n",
    "    \n",
    "           \n",
    "    mappingconfmat, mappingxticks, mappingplot = plotConfusionMatrix(\n",
    "    ytrue = test_labels,\n",
    "    ypred = test_predlabels,\n",
    "    test_dict=test_dict,\n",
    "    train_dict=train_dict,\n",
    "    type = 'mapping',\n",
    "    save_as = save_as,\n",
    "    title = 'ARI = {:.3f}, NCE = {:.3f}'.format(ARI, NCE),\n",
    "    xaxislabel =xaxislabel,\n",
    "    yaxislabel = yaxislabel,\n",
    "        re_order=re_order,\n",
    "    re_order_cols = re_order_cols,\n",
    "        re_index = re_index,\n",
    "    re_order_rows = re_order_rows,\n",
    "    ) \n",
    "    return mappingconfmat, mappingxticks, mappingplot\n",
    "      \n",
    "      \n",
    "#This helper method uses xgboost to train classifiers.\n",
    "def trainclassifier(train_anndata, common_top_genes, obs_id, train_dict, eta,\n",
    "                    max_cells_per_ident, train_frac, min_cells_per_ident):\n",
    "    \n",
    "    if sp.sparse.issparse(train_anndata.X):\n",
    "        if np.any(train_anndata.X.A<0):\n",
    "            raise Exception(\"Matrix contains negative values\")\n",
    "    else: \n",
    "        if np.any(train_anndata.X<0):\n",
    "            raise Exception(\"Matrix contains negative values\")\n",
    "\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    numbertrainclasses = len(train_anndata.obs[obs_id].values.categories)\n",
    "\n",
    "    xgb_params_train = {\n",
    "            'objective':'multi:softprob',\n",
    "            'eval_metric':'mlogloss',\n",
    "            'num_class':numbertrainclasses,\n",
    "            'eta':eta,\n",
    "            'max_depth':4,\n",
    "            'subsample': 0.6}\n",
    "    nround = 200\n",
    "    #Train XGBoost on 70% of training data and validate on the remaining data\n",
    "\n",
    "\n",
    "    training_set_train_70 = []\n",
    "    validation_set_train_70 = []\n",
    "    training_label_train_70 = []\n",
    "    validation_label_train_70 = []\n",
    "\n",
    "    #loop thru classes to split for training and validation\n",
    "    for i in train_anndata.obs[obs_id].values.categories:\n",
    "        \n",
    "        #how many cells in a class\n",
    "        cells_in_clust = train_anndata[train_anndata.obs[obs_id]==i,:].obs_names #cell names\n",
    "        n = min(max_cells_per_ident,round(len(cells_in_clust)*train_frac))\n",
    "        \n",
    "        #sample 70% for training and rest for validation\n",
    "        train_temp = np.random.choice(cells_in_clust,n,replace = False)\n",
    "        validation_temp = np.setdiff1d(cells_in_clust, train_temp)\n",
    "        \n",
    "        #upsample small clusters\n",
    "        if len(train_temp) < min_cells_per_ident:\n",
    "            train_temp_bootstrap = np.random.choice(train_temp, size = min_cells_per_ident - int(len(train_temp)))\n",
    "            train_temp = np.hstack([train_temp_bootstrap, train_temp])\n",
    "        \n",
    "        #store training and validation **names** of cells in vectors, which update for every class\n",
    "        training_set_train_70 = np.hstack([training_set_train_70,train_temp])\n",
    "        validation_set_train_70 = np.hstack([validation_set_train_70,validation_temp])\n",
    "        \n",
    "        #store training and validation **labels** of cells in vectors, which update for every class\n",
    "        training_label_train_70 = np.hstack([training_label_train_70,np.repeat(train_dict[i],len(train_temp))])\n",
    "        validation_label_train_70 = np.hstack([validation_label_train_70,np.repeat(train_dict[i],len(validation_temp))])\n",
    "\n",
    "        #need train_dict b/c XGboost needs number as class labels, not words\n",
    "        #this is only deconvulted later in plotting function\n",
    "        \n",
    "    #put data in XGB format\n",
    "    X_train = train_anndata[training_set_train_70,common_top_genes].X\n",
    "    train_matrix_train_70 = xgb.DMatrix(data = X_train, label = training_label_train_70, \n",
    "                                        feature_names = common_top_genes)\n",
    "    \n",
    "    X_valid = train_anndata[validation_set_train_70,common_top_genes].X\n",
    "    validation_matrix_train_70 = xgb.DMatrix(data = X_valid, label = validation_label_train_70, \n",
    "                                             feature_names = common_top_genes)\n",
    "\n",
    "    del training_set_train_70, validation_set_train_70, training_label_train_70\n",
    "    \n",
    "    #Train on 70%\n",
    "    bst_model_train_70 = xgb.train(\n",
    "        params = xgb_params_train,\n",
    "        dtrain = train_matrix_train_70,\n",
    "        num_boost_round = nround)\n",
    "    \n",
    "    #Validate on 30%\n",
    "    #a validation_cells x numclasses matrix, with each vector containing prob association with the classes\n",
    "    validation_pred_train_70 = bst_model_train_70.predict(data = validation_matrix_train_70)\n",
    "    \n",
    "    #for each cell, go through vec of probs and take index of max prob: that's assignment\n",
    "    valid_predlabels_train_70 = np.zeros((validation_pred_train_70.shape[0]))\n",
    "    for i in range(validation_pred_train_70.shape[0]):\n",
    "        valid_predlabels_train_70[i] = np.argmax(validation_pred_train_70[i,:])\n",
    "        \n",
    "    \n",
    "    #Train on 100%\n",
    "    #Train XGBoost on the full training data\n",
    "    training_set_train_full = []\n",
    "    training_label_train_full = []\n",
    "\n",
    "    for i in train_anndata.obs[obs_id].values.categories.values:\n",
    "        train_temp = train_anndata.obs.index[train_anndata.obs[obs_id].values == i]\n",
    "        if len(train_temp) < 100:\n",
    "            train_temp_bootstrap = np.random.choice(train_temp, size = 100 - int(len(train_temp)))\n",
    "            train_temp = np.hstack([train_temp_bootstrap, train_temp])\n",
    "        \n",
    "        #indices of cells in class\n",
    "        training_set_train_full = np.hstack([training_set_train_full,train_temp])\n",
    "        \n",
    "        #labels of cells in class: [label*N_class] stacked onto previous classes\n",
    "        training_label_train_full = np.hstack([training_label_train_full,np.repeat(train_dict[i],len(train_temp))])\n",
    "\n",
    "\n",
    "    X_train_full = train_anndata[training_set_train_full,common_top_genes].X\n",
    "    full_training_data = xgb.DMatrix(data = X_train_full, label = training_label_train_full, \n",
    "                                     feature_names = common_top_genes)\n",
    "\n",
    "    del training_set_train_full, training_label_train_full\n",
    "\n",
    "    bst_model_full_train = xgb.train(\n",
    "        params = xgb_params_train,\n",
    "        dtrain = full_training_data,\n",
    "        num_boost_round = nround)\n",
    "\n",
    "    \n",
    "    \n",
    "    print('trainclassifier() complete after', np.round(time.time() - start_time), 'seconds')\n",
    "    \n",
    "    \n",
    "    f1 = f1_score(validation_label_train_70, valid_predlabels_train_70, average = None)\n",
    "\n",
    "    \n",
    "    #real labels of validation set, predicted labels, classifier.\n",
    "    #recall these are all integers that are deconvulted later in plotting using the dicts\n",
    "    return validation_label_train_70, valid_predlabels_train_70, bst_model_full_train, f1\n",
    "\n",
    "\n",
    "#This helper method predicts the testing cluster labels.\n",
    "def predict(train_anndata, common_top_genes, bst_model_train_full, test_anndata, \n",
    "            train_obs_id, test_dict, test_obs_id):\n",
    "    \n",
    "    \n",
    "    if sp.sparse.issparse(train_anndata.X):\n",
    "        if np.any(train_anndata.X.A<0):\n",
    "            raise Exception(\"Training matrix contains negative values\")\n",
    "    else: \n",
    "        if np.any(train_anndata.X<0):\n",
    "            raise Exception(\"Training matrix contains negative values\")\n",
    "\n",
    "    if sp.sparse.issparse(test_anndata.X):\n",
    "        if np.any(test_anndata.X.A<0):\n",
    "            raise Exception(\"Testing matrix contains negative values\")\n",
    "    else: \n",
    "        if np.any(test_anndata.X<0):\n",
    "            raise Exception(\"Testing matrix contains negative values\")\n",
    "  \n",
    "    \n",
    "    #Predict the testing cluster labels\n",
    "    #how many classes mapping to \n",
    "    numbertrainclasses = len(train_anndata.obs[train_obs_id].values.categories)\n",
    "    \n",
    "    #put testing data into XGB format\n",
    "    full_testing_data = xgb.DMatrix(data = test_anndata[:,common_top_genes].X, \n",
    "                                    feature_names=common_top_genes)\n",
    "    \n",
    "    #a testing_cells x numclasses matrix, with each vector containing prob association with the classes\n",
    "    test_prediction = bst_model_train_full.predict(data = full_testing_data)\n",
    "\n",
    "    #for each cell, go through vec of probs and take index of max prob (if greater than ...): that's assignment\n",
    "\n",
    "    \n",
    "    test_predlabels = np.zeros((test_prediction.shape[0]))\n",
    "    for i in range(test_prediction.shape[0]):\n",
    "        if np.max(test_prediction[i, :]) > 1.1*(1/numbertrainclasses):\n",
    "            test_predlabels[i] = np.argmax(test_prediction[i,:])\n",
    "        \n",
    "        #\"unassigned\" is a label one larger than all b/c python begins indexing at 0\n",
    "        else:\n",
    "            test_predlabels[i] = numbertrainclasses\n",
    "        \n",
    "    test_labels = np.zeros(len(test_anndata.obs[test_obs_id].values))\n",
    "    for i,l in enumerate(test_anndata.obs[test_obs_id].values):\n",
    "        test_labels[i] = test_dict[l]\n",
    "\n",
    "    #actual labels of testing set, the labels that test set mapped to \n",
    "    return test_labels, test_predlabels, test_prediction\n",
    "\n",
    "def calculateNCE(labels_true,labels_pred):\n",
    "    X = labels_true\n",
    "    Y = labels_pred\n",
    "    contTable = confusion_matrix(X,Y)[0:len(np.unique(X)), 0:len(np.unique(Y))]\n",
    "    a = np.sum(contTable, axis = 1)\n",
    "    b = np.sum(contTable, axis = 0)\n",
    "    N = np.sum(contTable)\n",
    "    pij = contTable/N\n",
    "    pi = a/N\n",
    "    pj = b/N\n",
    "    Hyx = np.zeros(contTable.shape)\n",
    "    for i in range(contTable.shape[0]):\n",
    "        for j in range(contTable.shape[1]):\n",
    "          if pij[i,j] == 0:\n",
    "            Hyx[i,j] = 0\n",
    "          else:\n",
    "            Hyx[i,j] = pij[i,j]*np.log10(pij[i,j]/pi[i])\n",
    "    CE = -np.sum(Hyx)\n",
    "    Hyi = np.zeros(contTable.shape[1])\n",
    "    for j in range(contTable.shape[1]):\n",
    "      if pj[j] == 0:\n",
    "       Hyi[j] = 0\n",
    "      else:\n",
    "        Hyi[j] = pj[j]*np.log10(pj[j])\n",
    "    Hy = -np.sum(Hyi)\n",
    "    NCE = CE/Hy\n",
    "    return NCE\n",
    "\n",
    "def train_validate(adata, adata_cell,preproc=False):\n",
    "    if (preproc):\n",
    "        adata_cell.X = adata_cell.raw.X\n",
    "        sc.pp.highly_variable_genes(adata_cell, min_mean=0.0125, max_mean=3, min_disp=0.5) #HVGs\n",
    "\n",
    "    common_hvgs = list(set(adata[:,adata.var.highly_variable].var_names).intersection(set(adata_cell.var_names)))\n",
    "    adata_m_dict = make_dict(adata, obs_id='leiden')\n",
    "    adata_cell_dict = make_dict(adata_cell, obs_id='Subclass')\n",
    "    print(len(common_hvgs), 'Shared HVGs')\n",
    "\n",
    "    valid_truelabel_adata_cell, valid_predlabels_adata_cell, model_atlas_adata_cell = trainclassifier(train_anndata=adata_cell, \n",
    "                                                                                                 common_top_genes=common_hvgs, \n",
    "                                                                                                 obs_id='Subclass', \n",
    "                                                                                                 train_dict=adata_cell_dict, \n",
    "                                                                                                 eta=0.2,\n",
    "                                                                                                 max_cells_per_ident=1000, \n",
    "                                                                                          train_frac=0.7, \n",
    "                                                                                                 min_cells_per_ident=100)\n",
    "\n",
    "    plot_validation_plots(valid_truelabel_adata_cell, valid_predlabels_adata_cell, train_dict=adata_cell_dict)\n",
    "    \n",
    "    return model_atlas_adata_cell\n",
    "\n",
    "def pairwise_map(adata_t0, adata_t1, test_lab, train_lab, t0_dict, t1_dict, recomp_HVGs, min_cells,\n",
    "                x_lab, y_lab, union_hvgs):\n",
    "    adata_t0 = adata_t0.copy() \n",
    "    adata_t1 = adata_t1.copy() \n",
    "    adata_t0.X = adata_t0.raw.X\n",
    "    adata_t1.X = adata_t1.raw.X\n",
    "    \n",
    "    if (recomp_HVGs):\n",
    "        sc.pp.highly_variable_genes(adata_t0, min_mean=0.0125, max_mean=3, min_disp=0.5) #HVGs\n",
    "        sc.pp.highly_variable_genes(adata_t1, min_mean=0.0125, max_mean=3, min_disp=0.5) #HVGs\n",
    "        t0_hvgs = list(adata_t0[:, adata_t0.var.highly_variable].var_names)\n",
    "        t1_hvgs = list(adata_t1[:, adata_t1.var.highly_variable].var_names)\n",
    "        \n",
    "        if (union_hvgs):\n",
    "            t0_t1hvgs_ = list(set(t0_hvgs).union(t1_hvgs))\n",
    "            data_inter = list(set(adata_t1.var_names).intersection(set(adata_t0.var_names)))\n",
    "            t0_t1hvgs = list(set(data_inter).intersection(set(t0_t1hvgs_)))\n",
    "\n",
    "        else:\n",
    "            t0_t1hvgs = list(set(t0_hvgs).intersection(t1_hvgs))\n",
    "\n",
    "    \n",
    "    else:\n",
    "        t0_hvgs = list(adata_t0[:, adata_t0.var.highly_variable].var_names)\n",
    "        t1_hvgs = list(adata_t1[:, adata_t1.var.highly_variable].var_names)\n",
    "        t0_t1hvgs = list(set(t0_hvgs).intersection(t1_hvgs))\n",
    "\n",
    "    print(len(t0_t1hvgs), 'shared HVGs')\n",
    "    \n",
    "    validation_label_train_70t0vst1, valid_predlabels_train_70t0vst1, model_t1,model_f1 = trainclassifier(train_anndata=adata_t1, \n",
    "                                                                                                 common_top_genes=t0_t1hvgs, \n",
    "                                                                                                 obs_id=train_lab, \n",
    "                                                                                                 train_dict=t1_dict, \n",
    "                                                                                                 eta=0.2,\n",
    "                                                                                                 max_cells_per_ident=1000, \n",
    "                                                                                          train_frac=0.7, \n",
    "                                                                                                min_cells_per_ident=min_cells)\n",
    "\n",
    "    plot_validation_plots(validation_label_train_70t0vst1, valid_predlabels_train_70t0vst1, train_dict=t1_dict)\n",
    "\n",
    "    test_labelst0vst1, test_predlabelst0vst1, test_prediction_t0vst1 = predict(train_anndata=adata_t1, \n",
    "                                                                     common_top_genes=model_t1.feature_names, \n",
    "                                                                     bst_model_train_full=model_t1, \n",
    "                                                                     test_anndata=adata_t0,\n",
    "                                                                     train_obs_id=train_lab, \n",
    "                                                                     test_dict=t0_dict, \n",
    "                                                                     test_obs_id=test_lab)\n",
    "\n",
    "    mappingconfmatt0vst1, mappingxtickst0vst1, mappingplott0vst1 = plot_mapping(test_labels=test_labelst0vst1, \n",
    "                 test_predlabels=test_predlabelst0vst1, \n",
    "                 test_dict=t0_dict, \n",
    "                 train_dict=t1_dict,\n",
    "                     xaxislabel=x_lab, yaxislabel=y_lab,)\n",
    "    \n",
    "    test_items = test_labelst0vst1, test_predlabelst0vst1, test_prediction_t0vst1\n",
    "    mapping_items = mappingconfmatt0vst1, mappingxtickst0vst1, mappingplott0vst1\n",
    "    \n",
    "    return test_items, mapping_items\n",
    "\n",
    "def make_colors(PX_dict):\n",
    "    PX_colors = []\n",
    "    for i in PX_dict:\n",
    "        for j in colors_subclass:\n",
    "            if (j in i):\n",
    "                PX_colors.append(colors_subclass[j])\n",
    "    return PX_colors\n",
    "\n",
    "def rem_fem(adata):\n",
    "    for j in list(adata.obs.Type_nn_dists.values.categories):\n",
    "        if ('Fem' in j):\n",
    "            adata = adata[adata.obs['Type_nn_dists']!=j,:]\n",
    "            adata = adata[adata.obs['Type_leiden']!=j,:]\n",
    "    return adata\n",
    "\n",
    "def list2dict(list_in):\n",
    "\n",
    "    adata_dict = {}\n",
    "    for num,i in enumerate(list_in):\n",
    "        adata_dict[i] = num\n",
    "        \n",
    "    #adata_dict['Unassigned'] = num + 1\n",
    "    \n",
    "    return adata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_items, mapping_items = pairwise_map(adata_t0=P12_FF_gaba, adata_t1=P22_gaba,test_lab='Type',\n",
    "                                                                            train_lab='Type', \n",
    "                                                                          recomp_HVGs=True, union_hvgs=False,\n",
    "                                         t0_dict=make_dict(P12_FF_gaba, 'Type'),\n",
    "                                         t1_dict=make_dict(P22_gaba, 'Type'),\n",
    "                                        min_cells=100, x_lab='P22 Sham', y_lab='P12_FF Sham')\n",
    "\n",
    "test_labelsP12_FFvsP22, test_predlabelsP12_FFvsP22, test_prediction_P12_FFvsP22 = test_items\n",
    "mappingconfmatP12_FFvsP22, mappingxticksP12_FFvsP22_sub, mappingplotP12_FFvsP22 = mapping_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labelsP12_FFvsP22, test_predlabelsP12_FFvsP22, test_prediction_P12_FFvsP22 = test_items\n",
    "mappingconfmatP12_FFvsP22, mappingxticksP12_FFvsP22_sub, mappingplotP12_FFvsP22 = mapping_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = make_dict(P22_gaba, 'Type')\n",
    "P12_FF_gaba.obs['P22 Mapping Prob'] = np.max(test_prediction_P12_FFvsP22, axis=1)\n",
    "P12_FF_gaba.obs['P22 Mapping Label'] = pd.Categorical(test_predlabelsP12_FFvsP22).rename_categories(list(a.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P12_FF_gaba.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type_cols = sn.color_palette('pastel').as_hex()+sn.color_palette('Set2').as_hex()+sn.color_palette('Set3').as_hex()+sn.color_palette('hls').as_hex()+sn.color_palette('husl').as_hex()\n",
    "sc.set_figure_params(dpi_save=300)\n",
    "sc.pl.umap(P12_FF_gaba, color=['Type',], legend_loc='on data', \n",
    "           legend_fontsize=10, palette=type_cols, legend_fontweight='semibold',s=30, \n",
    "           frameon=False,\n",
    "           title= 'P22 1d WD: XXXX GABAergic Neurons',\n",
    "           add_outline=True, save='P22_1-dWD_gaba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P22_gaba.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "type_cols = sn.color_palette('pastel').as_hex()+sn.color_palette('Set2').as_hex()+sn.color_palette('Set3').as_hex()+sn.color_palette('hls').as_hex()+sn.color_palette('husl').as_hex()\n",
    "sc.set_figure_params(dpi_save=300)\n",
    "sc.pl.umap(P22_gaba, color=['Type',], legend_loc='on data', \n",
    "           legend_fontsize=10, palette=type_cols, legend_fontweight='semibold',s=30, \n",
    "           frameon=False,\n",
    "           title= 'P22: 4888 GABAergic Neurons',\n",
    "           add_outline=True, save='P22_gaba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.pl.umap(P12_FF_gaba, color=['Type','P22 Mapping Prob','P22 Mapping Label', 'Baz1a',\n",
    "                           'Trpc6', 'Igfn1'], legend_loc='on data', legend_fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P22_gaba.obs.Subclass.values.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P22_gaba.obs['Sub'] = P22_gaba.obs['Subclass'].cat.rename_categories(['L2/3', 'L4', 'L4/5IT', 'L5NP', \n",
    "                                                                      'L5PT', 'L6CT', 'L6IT', 'L6b'])\n",
    "P12_FF_gaba.obs['Sub'] = P12_FF_gaba.obs['Subclass'].cat.rename_categories(['L2/3', 'L4', 'L4/5IT', 'L5NP', \n",
    "                                                                      'L5PT', 'L6CT', 'L6IT', 'L6b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "lims = [0.65, 0.35, 0.18, 0.43]\n",
    "low_lims = [0, 0,0,0]\n",
    "for i in ['Lamp5', 'Pvalb', 'Sst', 'Vip']:\n",
    "    print(i)\n",
    "    a=P22_gaba[P22_gaba.obs['Subclass'].str.startswith(i),:]\n",
    "    b=P12_FF_gaba[P12_FF_gaba.obs['Subclass'].str.startswith(i),:]\n",
    "    \n",
    "    xx = a.obs['Type'].value_counts(normalize=True)\n",
    "    yy = b.obs['P22 Mapping Label'].value_counts(normalize=True)\n",
    "    \n",
    "    #print(b.obs['P22 Mapping Label'].value_counts())\n",
    "    \n",
    "#     if (i=='L4'):\n",
    "#         freq_scatter(x=xxx[0:4], y=yy[0:4],\n",
    "#             x_lab='P22 Type Freqs', y_lab='P12_FF Types Mapping Freq', hue_='Types', unity_lim=lims[c], \n",
    "#                  low_lim=low_lims[c])\n",
    "#         oh=xxx\n",
    "#         my=yy\n",
    "    \n",
    "    freq_scatter(x=xx[xx.index.str.startswith(i)],\n",
    "            y=yy[yy.index.str.startswith(i)],\n",
    "            x_lab='P22 Type Freqs', y_lab='P12_FF Types Mapping Freq', hue_='Types', unity_lim=lims[c], \n",
    "                 low_lim=low_lims[c])\n",
    "    plt.legend(ncol=1, bbox_to_anchor=(1,1))\n",
    "    plt.show()\n",
    "    c = c +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P22_gaba.obs['Type'].values.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_gab = ['Pvalb_A', 'Pvalb_B', 'Pvalb_C',\n",
    "       'Pvalb_D', 'Pvalb_E', 'Sst_A', 'Sst_B', 'Sst_C', 'Sst_D', 'Sst_E',\n",
    "       'Sst_F', 'Sst_G', 'Sst_H', 'Sst_I', 'Vip_A', 'Vip_B', 'Vip_C', 'Vip_D',\n",
    "       'Vip_E','Lamp5_A', 'Lamp5_B', 'Lamp5_C',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq_scatter(x=P22_gaba.obs['Type'].value_counts(normalize=True),\n",
    "            y= P12_FF_gaba.obs['P22 Mapping Label'].value_counts(normalize=True),\n",
    "            x_lab='P22 Type Frequency', y_lab='10d AWD Type Frequency', hue_='Types', unity_lim=0.15, low_lim=0,\n",
    "            hue_ord = ord_gab)\n",
    "plt.savefig('figures/gaba_10dWD_freqs.pdf',  bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2/3 PC analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA on type markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These objs grabbed from gluta sub-by-sub mapping section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_FF = sc.read_h5ad('h5ads_cmprsd/P12_FF_L23_mappedP22.h5ad')\n",
    "L23_P22 = sc.read_h5ad('h5ads_cmprsd/P22_L23.h5ad')\n",
    "\n",
    "L23_FF.X = L23_FF.raw.X\n",
    "L23_P22.X = L23_P22.raw.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.boxenplot(data=L23_P22.obs, x='Sample', y='total_counts')\n",
    "plt.show()\n",
    "sn.boxenplot(data=L23_P22.obs, x='Sample', y='n_genes_by_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.boxenplot(data=L23_FF.obs, x='Sample', y='total_counts')\n",
    "plt.show()\n",
    "sn.boxenplot(data=L23_FF.obs, x='Sample', y='n_genes_by_counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_P22 = L23_P22[L23_P22.obs.Sample!='S3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_FF.obs['P22 Mapping Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_P22_marks = []\n",
    "for i in L23_P22.obs['Type'].values.categories:\n",
    "    L23_P22_marks.append(DE(L23_P22,obs_id='Type', obs_id_test=i, ref='rest', \n",
    "                            pts_thresh=0.2, lf_thresh=0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L23_FF.X, L23_P22.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marks = list(L23_P22_marks[0].index)+list(L23_P22_marks[1].index)+list(L23_P22_marks[2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute scores here now relative to all genes instead of before relative to only 489 markers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=module_score(L23_FF, genes_use=L23_P22_marks[0].index, score_name='A Score', verbose = True)\n",
    "x=module_score(L23_FF, genes_use=L23_P22_marks[1].index, score_name='B Score', verbose = True)\n",
    "x=module_score(L23_FF, genes_use=L23_P22_marks[2].index, score_name='C Score', verbose = True)\n",
    "\n",
    "x=module_score(L23_P22, genes_use=L23_P22_marks[0].index, score_name='A Score', verbose = True)\n",
    "x=module_score(L23_P22, genes_use=L23_P22_marks[1].index, score_name='B Score', verbose = True)\n",
    "x=module_score(L23_P22, genes_use=L23_P22_marks[2].index, score_name='C Score', verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Baz1a' in marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L23_P22 = L23_P22[:,marks+['Baz1a']]\n",
    "L23_FF = L23_FF[:,marks+['Baz1a']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L23_P22.var['highly_variable'] = L23_P22.shape[1]*[True]\n",
    "L23_FF.var['highly_variable'] = L23_FF.shape[1]*[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_FF.raw = L23_FF\n",
    "sc.pp.scale(L23_FF, max_value=10) #scale\n",
    "sc.tl.pca(L23_FF, svd_solver='arpack') #run PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_P22.raw = L23_P22\n",
    "sc.pp.scale(L23_P22, max_value=10) #scale\n",
    "sc.tl.pca(L23_P22, svd_solver='arpack',) #run PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca_variance_ratio(L23_FF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca_variance_ratio(L23_P22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca(shuffle(L23_FF), color=['P22 Mapping Label','Sample'],  components=['1,2', '2,3', '3,4',], ncols=3,\n",
    "         legend_loc='on data', add_outline=True, outline_width=(0.2,0.05), s=20, )\n",
    "sc.pl.pca(shuffle(L23_P22), color=['Type', 'Sample'],  components=['1,2', '2,3', '3,4',], ncols=3,\n",
    "         legend_loc='on data',add_outline=True,outline_width=(0.2,0.05), s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_P22.raw.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_FF.raw.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L23_FF.raw.X.A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define your 100x2 matrix\n",
    "points = L23_FF.obsm['X_pca']\n",
    "\n",
    "# Extract the first two columns\n",
    "points_2d = points[:, :2]\n",
    "\n",
    "# Define the rotation matrix\n",
    "theta = np.radians(-190)\n",
    "rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n",
    "\n",
    "# Define the reflection matrix\n",
    "#reflection_matrix = np.array([[-1, 0], [0, 1]])\n",
    "\n",
    "# Combine rotation and reflection into a single transformation matrix\n",
    "#combined_matrix = np.dot(reflection_matrix, rotation_matrix)\n",
    "\n",
    "# Apply combined transformation to the first two columns\n",
    "transformed_points_2d = np.dot(points_2d, rotation_matrix.T)\n",
    "\n",
    "# Replace the transformed columns back into the original matrix\n",
    "transformed_points = np.copy(points)\n",
    "transformed_points[:, :2] = transformed_points_2d\n",
    "\n",
    "\n",
    "L23_FF.obsm['X_pca_rot'] = transformed_points\n",
    "\n",
    "axes = [sc.pl.embedding(L23_FF, color=['P22 Mapping Label'],\n",
    "         legend_loc='on data', add_outline=True, outline_width=(0.2,0.05), s=20,basis='X_pca_rot',\n",
    "                     cmap='hot',title='P12 Cells: P22 Labels', show=False),\n",
    "        sc.pl.embedding(shuffle(L23_FF), color=['P22 Mapping Label'],\n",
    "         legend_loc='on data', add_outline=True, outline_width=(0.2,0.05), s=20, components=['2,3'],\n",
    "                        basis='X_pca_rot',\n",
    "                     cmap='hot',title='P12 Cells: P22 Labels', show=False),\n",
    "        sc.pl.embedding(L23_P22, color=['Type'],\n",
    "         legend_loc='on data', add_outline=True, outline_width=(0.2,0.05), s=20,basis='X_pca',\n",
    "                     cmap='hot', title='P22 Cells: Mature Types', show=False),\n",
    "       sc.pl.embedding(L23_P22, color=['Type'],\n",
    "         legend_loc='on data', add_outline=True, outline_width=(0.2,0.05), s=20,basis='X_pca',\n",
    "                     cmap='hot', title='P22 Cells: Mature Types',  components=['2,3'], show=False)]\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim([-15,15])\n",
    "    ax.set_ylim([-15,15])\n",
    "    ax.set_xticks(np.arange(-15,16,5))\n",
    "    ax.set_yticks(np.arange(-15,16,5))\n",
    "    #ax.set_title('P12: Colored by P22 Mapping')\n",
    "    ax.grid(True, linewidth=0.5)\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given the results above, we can safely call X_pca with X_pca_rot.\n",
    "\n",
    "L23_FF.obsm['X_pca'] = transformed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = L23_FF.varm['PCs']\n",
    "\n",
    "# Extract the first two columns\n",
    "points_2d = points[:, :2]\n",
    "\n",
    "# Define the rotation matrix\n",
    "theta = np.radians(-190)\n",
    "rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n",
    "\n",
    "# Define the reflection matrix\n",
    "#reflection_matrix = np.array([[-1, 0], [0, 1]])\n",
    "\n",
    "# Combine rotation and reflection into a single transformation matrix\n",
    "#combined_matrix = np.dot(reflection_matrix, rotation_matrix)\n",
    "\n",
    "# Apply combined transformation to the first two columns\n",
    "transformed_points_2d = np.dot(points_2d, rotation_matrix.T)\n",
    "\n",
    "# Replace the transformed columns back into the original matrix\n",
    "transformed_points = np.copy(points)\n",
    "transformed_points[:, :2] = transformed_points_2d\n",
    "\n",
    "\n",
    "L23_FF.varm['PCs_rot'] = transformed_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_FF.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.pp.scale(L23_FF, max_value=10) #scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_FF.obsm['X_pca_P22'] = np.matmul(L23_FF.X, L23_P22.varm['PCs'][:,0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(L23_FF.obsm['X_pca_P22'][:,0], L23_FF.obsm['X_pca_P22'][:,1], s=3)\n",
    "plt.xlim([-16,16])\n",
    "plt.ylim([-15,15])\n",
    "plt.title('P22 10d-WD')\n",
    "plt.show()\n",
    "plt.scatter(L23_P22.obsm['X_pca'][:,0], L23_P22.obsm['X_pca'][:,1], s=3)\n",
    "plt.xlim([-16,16])\n",
    "plt.ylim([-15,15])\n",
    "plt.title('P22')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_FF.obsm['X_pca_P22'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_FF.obs['PC1'] = L23_FF.obsm['X_pca_P22'][:,0]\n",
    "L23_FF.obs['PC2'] = L23_FF.obsm['X_pca_P22'][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_P22.obs['PC1'] = L23_P22.obsm['X_pca'][:,0]\n",
    "L23_P22.obs['PC2'] = L23_P22.obsm['X_pca'][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sc.pl.scatter(adata=L23_FF,\n",
    "              x='PC1', \n",
    "              y='PC2', color='P22 Mapping Label',legend_loc='on data',\n",
    "                   show=False)\n",
    "ax.set_xlim([-15,15])\n",
    "ax.set_ylim([-15,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sc.pl.embedding(shuffle(L23_FF), color=['P22 Mapping Label'],\n",
    "         legend_loc='on data', add_outline=True, outline_width=(0.2,0.05), s=20,basis='X_pca_rot',\n",
    "                     palette=sn.color_palette('Set2').as_hex()[0:3],\n",
    "              show=False)\n",
    "ax.set_xlim([-15,15])\n",
    "ax.set_ylim([-15,15])\n",
    "ax.set_xticks(np.arange(-15,16,5))\n",
    "ax.set_yticks(np.arange(-15,16,5))\n",
    "ax.set_title('P22 10d-WD: Colored by P22 Mapping')\n",
    "ax.set_xlabel('ref_P22_PC1')\n",
    "ax.set_ylabel('ref_P22_PC2')\n",
    "\n",
    "plt.grid(False)\n",
    "plt.savefig('figures/Fig6E_P12types.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sc.pl.embedding(shuffle(L23_P22_sub), color=['Type'],\n",
    "         legend_loc='on data', add_outline=True, outline_width=(0.2,0.05), s=20,basis='X_pca',\n",
    "                     palette=sn.color_palette('Set2').as_hex()[0:3],\n",
    "              show=False)\n",
    "ax.set_xlim([-15,15])\n",
    "ax.set_ylim([-15,15])\n",
    "ax.set_xticks(np.arange(-15,16,5))\n",
    "ax.set_yticks(np.arange(-15,16,5))\n",
    "ax.set_title('P22: Colored by Type Label')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "\n",
    "plt.grid(False)\n",
    "plt.savefig('figures/Fig6E_P22types.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = [sc.pl.embedding(L23_FF, color=['P22 Mapping Label'],\n",
    "         legend_loc='on data', add_outline=True, outline_width=(0.2,0.05), s=20,basis='X_pca_rot',\n",
    "                     cmap='hot',title='P22 10d AWD: Colored by P22 Mapping',palette=sn.color_palette('Set2').as_hex()[0:3], show=False),\n",
    "        sc.pl.embedding(shuffle(L23_FF), color=['P22 Mapping Label'],\n",
    "         legend_loc='on data', add_outline=True, outline_width=(0.2,0.05), s=20, palette=sn.color_palette('Set2').as_hex()[0:3],components=['2,3'],\n",
    "                        basis='X_pca_rot',\n",
    "                     cmap='hot',title='P22 10d AWD: Colored by P22 Mapping', show=False),]\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim([-15,15])\n",
    "    ax.set_ylim([-15,15])\n",
    "    ax.set_xticks(np.arange(-15,16,5))\n",
    "    ax.set_yticks(np.arange(-15,16,5))\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    #ax.set_title('P12: Colored by P22 Mapping')\n",
    "    ax.grid(False,)\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = [sc.pl.embedding(L23_FF, color=['P22 Mapping Label'],\n",
    "         legend_loc='on data', add_outline=True, outline_width=(0.2,0.05), s=20,basis='X_pca_rot',\n",
    "                     cmap='hot',title='P22 10d-WD: Colored by P22 Mapping',palette=sn.color_palette('Set2').as_hex()[0:3], show=False),\n",
    "        sc.pl.embedding(shuffle(L23_FF), color=['P22 Mapping Label'],\n",
    "         legend_loc='on data', add_outline=True, outline_width=(0.2,0.05), s=20, palette=sn.color_palette('Set2').as_hex()[0:3],components=['2,3'],\n",
    "                        basis='X_pca_rot',\n",
    "                     cmap='hot',title='P22 10d-WD: Colored by P22 Mapping', show=False),\n",
    "        sc.pl.embedding(L23_P22_sub, color=['Type'],\n",
    "         legend_loc='on data', add_outline=True, outline_width=(0.2,0.05),palette=sn.color_palette('Set2').as_hex()[0:3], s=20,basis='X_pca',\n",
    "                     cmap='hot', title='P22: Colored by Type Label', show=False),\n",
    "       sc.pl.embedding(L23_P22_sub, color=['Type'],\n",
    "         legend_loc='on data', add_outline=True, outline_width=(0.2,0.05), palette=sn.color_palette('Set2').as_hex()[0:3],s=20,basis='X_pca',\n",
    "                     cmap='hot', title='P22: Colored by Type Label',  components=['2,3'], show=False)]\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim([-15,15])\n",
    "    ax.set_ylim([-15,15])\n",
    "    ax.set_xticks(np.arange(-15,16,5))\n",
    "    ax.set_yticks(np.arange(-15,16,5))\n",
    "    #ax.set_title('P12: Colored by P22 Mapping')\n",
    "    ax.grid(True, linewidth=0.5)\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(10,5.5))\n",
    "axs[0].scatter(L23_FF.obsm['X_pca_P22'][:,0], L23_FF.obsm['X_pca_P22'][:,1],\n",
    "              s=40, color='grey')\n",
    "\n",
    "sn.kdeplot(L23_FF.obsm['X_pca_P22'][:,0], L23_FF.obsm['X_pca_P22'][:,1],\n",
    "             cmap=\"hot\", shade=True, bw_adjust=0.7, alpha=0.7,ax=axs[0],)\n",
    "axs[0].set_xlim([-20,20])\n",
    "axs[0].set_ylim([-20,20])\n",
    "axs[0].set_title('P12_FF')\n",
    "axs[0].set_xlabel('ref_PC1')\n",
    "axs[0].set_ylabel('ref_PC2')\n",
    "\n",
    "axs[1].scatter(L23_P22.obsm['X_pca'][:,0], L23_P22.obsm['X_pca'][:,1],\n",
    "              s=40, color='grey')\n",
    "sn.kdeplot(L23_P22.obsm['X_pca'][:,0], L23_P22.obsm['X_pca'][:,1],\n",
    "          cmap=\"hot\", shade=True, bw_adjust=0.7, alpha=0.7, ax=axs[1])\n",
    "axs[1].set_xlim([-20,20])\n",
    "axs[1].set_ylim([-20,20])\n",
    "axs[1].set_title('P22')\n",
    "axs[1].set_xlabel('ref_PC1')\n",
    "axs[1].set_ylabel('ref_PC2')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "axs[0].scatter(L23_FF.obsm['X_pca_P22'][:,1], L23_FF.obsm['X_pca_P22'][:,2],\n",
    "              s=40, color='grey')\n",
    "\n",
    "sn.kdeplot(L23_FF.obsm['X_pca_P22'][:,1], L23_FF.obsm['X_pca_P22'][:,2],\n",
    "             cmap=\"hot\", shade=True, bw_adjust=0.7, alpha=0.7,ax=axs[0],)\n",
    "axs[0].set_xlim([-16,16])\n",
    "axs[0].set_ylim([-15,15])\n",
    "axs[0].set_title('P12_FF')\n",
    "axs[0].set_xlabel('ref_PC2')\n",
    "axs[0].set_ylabel('ref_PC3')\n",
    "\n",
    "axs[1].scatter(L23_P22.obsm['X_pca'][:,1], L23_P22.obsm['X_pca'][:,2],\n",
    "              s=40, color='grey')\n",
    "sn.kdeplot(L23_P22.obsm['X_pca'][:,1], L23_P22.obsm['X_pca'][:,2],\n",
    "          cmap=\"hot\", shade=True, bw_adjust=0.7, alpha=0.7, ax=axs[1])\n",
    "axs[1].set_xlim([-16,16])\n",
    "axs[1].set_ylim([-15,15])\n",
    "axs[1].set_title('P22')\n",
    "axs[1].set_xlabel('ref_PC2')\n",
    "axs[1].set_ylabel('ref_PC3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ABC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_FF.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_FF.raw.X, L23_P22.raw.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = sc.pl.embedding(shuffle(L23_FF), color=['A Score', 'B Score', 'C Score'],\n",
    "         legend_loc='on data', add_outline=True, outline_width=(0.1,0.05), s=30,basis='X_pca_rot',\n",
    "                     cmap='hot',sort_order=False, vmin=0, vmax=1,\n",
    "              show=False)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim([-15,15])\n",
    "    ax.set_ylim([-15,15])\n",
    "    ax.set_xticks(np.arange(-15,16,5))\n",
    "    ax.set_yticks(np.arange(-15,16,5))\n",
    "    #ax.set_title('P12: Colored by P22 Mapping')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.grid(False)\n",
    "axes[0].set_xlabel('PC1')\n",
    "axes[0].set_ylabel('PC2')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('figures/Fig6E_P12.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_P22_sub = sc.pp.subsample(L23_P22, n_obs = L23_FF.shape[0], copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "axes = sc.pl.embedding(L23_P22_sub, color=['A Score', 'B Score', 'C Score'],\n",
    "         legend_loc='on data', add_outline=True, outline_width=(0.1,0.05), s=30,basis='X_pca',\n",
    "                     cmap='hot',sort_order=False, vmin=0, vmax=1,\n",
    "              show=False)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim([-15,15])\n",
    "    ax.set_ylim([-15,15])\n",
    "    ax.set_xticks(np.arange(-15,16,5))\n",
    "    ax.set_yticks(np.arange(-15,16,5))\n",
    "    #ax.set_title('P12: Colored by P22 Mapping')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.grid(False)\n",
    "axes[0].set_xlabel('PC1')\n",
    "axes[0].set_ylabel('PC2')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('figures/Fig6E_P22.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save projected objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_FF.write_h5ad('h5ads_cmprsd/P12_FF_L23_mappedP22_proj.h5ad')\n",
    "L23_P22.write_h5ad('h5ads_cmprsd/P22_L23_projFF.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PC feature plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this contains 20k genes\n",
    "adata = sc.read_h5ad('h5ads_cmprsd/P22_L23.h5ad')\n",
    "adata = adata[adata.obs.Sample!='S3']\n",
    "L23_P22_marks = []\n",
    "for i in adata.obs['Type'].values.categories:\n",
    "    L23_P22_marks.append(DE(adata,obs_id='Type', obs_id_test=i, ref='rest', \n",
    "                            pts_thresh=0.2, lf_thresh=0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these only contain 489 ABC markers\n",
    "L23_FF = sc.read_h5ad('h5ads_cmprsd/P12_FF_L23_mappedP22_proj.h5ad')\n",
    "L23_P22 = sc.read_h5ad('h5ads_cmprsd/P22_L23_projFF.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_FF.var_names_make_unique()\n",
    "L23_P22.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc.pl.pca_variance_ratio(L23_FF, )\n",
    "sc.pl.pca_variance_ratio(L23_P22,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(30),100*L23_FF.uns['pca']['variance'][0:30]/sum(L23_FF.uns['pca']['variance'][0:30]),\n",
    "           label='L2/3 P22 10d AWD')\n",
    "plt.scatter(np.arange(30),100*L23_P22.uns['pca']['variance'][0:30]/sum(L23_P22.uns['pca']['variance'][0:30]),\n",
    "           label='L2/3 P22')\n",
    "plt.xlabel('PC Rank')\n",
    "plt.legend()\n",
    "plt.ylabel('Percent Variance Explained (%)')\n",
    "plt.savefig('figures/varPCs_10d.pdf',  bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0)  # For reproducibility\n",
    "A = L23_P22.varm['PCs'][:,0:10]\n",
    "B = L23_P22.varm['PCs'][:,0:10]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sn.heatmap((A.T.dot(B)), annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt=\".1f\")\n",
    "plt.title('Correlation Heatmap of PCs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0)  # For reproducibility\n",
    "A = L23_P22.varm['PCs'][:,0:4]\n",
    "B = L23_FF.varm['PCs_rot'][:,0:4]\n",
    "\n",
    "n, c = A.shape\n",
    "\n",
    "corr_matrix = A.T.dot(B)\n",
    "\n",
    "corr_df = pd.DataFrame(corr_matrix, index=[f'PC{i+1}' for i in range(c)], columns=[f'PC{i+1}' for i in range(c)])\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(4, 3))\n",
    "sn.heatmap(corr_df, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt=\".2f\")\n",
    "plt.title('Correlation of PCs')\n",
    "plt.xlabel('P22 10d AWD')\n",
    "plt.ylabel('P22')\n",
    "plt.savefig('figures/corrPCs_10d.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = L23_P22.varm['PCs'][:,1]\n",
    "B = L23_FF.varm['PCs_rot'][:,1]\n",
    "\n",
    "A.T.dot(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def pca_heatmap_raw(adata, component, use_raw=None, layer=None, groupby='Type', frac_top=0.33):\n",
    "    attr = 'varm'\n",
    "    keys = 'PCs'\n",
    "    scores = getattr(adata, attr)[keys][:, component]\n",
    "    dd = pd.DataFrame(scores, index=adata.var_names)\n",
    "    var_names_pos = dd.sort_values(0, ascending=False).index[:20]\n",
    "\n",
    "    var_names_neg = dd.sort_values(0, ascending=True).index[:20]\n",
    "\n",
    "    pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index)\n",
    "\n",
    "    bottom_cells = pd2.sort_values(0).index[:int(frac_top*L23_P12.shape[0])].tolist()\n",
    "    top_cells = pd2.sort_values(0, ascending=False).index[:int(frac_top*L23_P12.shape[0])].tolist()\n",
    "    adat_use = adata[top_cells+bottom_cells]\n",
    "    sc.pl.heatmap(adat_use, list(var_names_pos) + list(var_names_neg), \n",
    "                        show_gene_labels=True,\n",
    "                        swap_axes=True, cmap='hot', \n",
    "                        use_raw=False, layer=layer, figsize=(3,8), groupby=groupby,standard_scale='var')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def annot_bar(adata, groupby,bar_position='bottom'):\n",
    "    adata.obs['typecol'] = adata.obs[groupby].cat.rename_categories(sn.color_palette('Set2').as_hex()[0:3])\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    from  matplotlib.cm import ScalarMappable\n",
    "    from  matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "    import numpy as np\n",
    "\n",
    "    vals = np.arange(adata.shape[0])\n",
    "    cols = list(adata.obs['typecol'].values)\n",
    "    bounds = np.append(vals, vals[-1] + 1)\n",
    "\n",
    "    cmap = ListedColormap(cols)\n",
    "    norm = BoundaryNorm(bounds, ncolors=len(cols))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(3, 1))\n",
    "    fig.subplots_adjust(bottom=0.75)\n",
    "    \n",
    "    if bar_position == 'bottom':\n",
    "        orientation = 'horizontal'\n",
    "        pad = 0.1\n",
    "        shrink = 1.0\n",
    "    elif bar_position == 'top':\n",
    "        orientation = 'horizontal'\n",
    "        pad = 0.1\n",
    "        shrink = 1.0\n",
    "    elif bar_position == 'left':\n",
    "        orientation = 'vertical'\n",
    "        pad = 0.1\n",
    "        shrink = 1.0\n",
    "    elif bar_position == 'right':\n",
    "        orientation = 'vertical'\n",
    "        pad = 0.1\n",
    "        shrink = 1.0\n",
    "    else:\n",
    "        raise ValueError(\"Invalid bar_position. Use 'bottom', 'top', 'left', or 'right'.\")\n",
    "    \n",
    "    cb = fig.colorbar(ScalarMappable(norm=norm, cmap=cmap),\n",
    "                 cax=ax, orientation='horizontal', label=groupby)\n",
    "    cb.set_ticks([])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def annot_bar_var(gene_list, groupby='Type'):\n",
    "    \n",
    "    \n",
    "    categories = []\n",
    "    for i in gene_list:\n",
    "    \n",
    "        \n",
    "        if (i.split('-')[0] in L23_P22_marks[0].index): categories.append('A')\n",
    "        elif (i.split('-')[0] in L23_P22_marks[1].index): categories.append('B')\n",
    "        elif (i.split('-')[0] in L23_P22_marks[2].index): categories.append('C')\n",
    "    \n",
    "    \n",
    "    a = pd.Categorical(categories)\n",
    "    print(a)\n",
    "    b = a.rename_categories(sn.color_palette('Set2').as_hex()[0:3])\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    from  matplotlib.cm import ScalarMappable\n",
    "    from  matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "    import numpy as np\n",
    "\n",
    "    vals = np.arange(len(gene_list))\n",
    "    cols = list(b)\n",
    "    bounds = np.append(vals, vals[-1] + 1)\n",
    "\n",
    "    cmap = ListedColormap(cols)\n",
    "    norm = BoundaryNorm(bounds, ncolors=len(cols))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(0.2, 12))\n",
    "    #fig.subplots_adjust(bottom=0.75)\n",
    "    \n",
    "    cb = fig.colorbar(ScalarMappable(norm=norm, cmap=cmap),\n",
    "                 cax=ax, orientation='vertical',)\n",
    "    cb.set_ticks([])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def cumulative_count_shuff(data):\n",
    "    \n",
    "    cum_A = np.cumsum(data == 'L2/3_A')\n",
    "    cum_B = np.cumsum(data == 'L2/3_B')\n",
    "    cum_C = np.cumsum(data == 'L2/3_C')\n",
    "\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    plt.plot(cum_A, label='L2/3_A', drawstyle='steps-post', color=sn.color_palette('Set2').as_hex()[0], linewidth=3)\n",
    "    plt.plot(cum_B, label='L2/3_B', drawstyle='steps-post',color= sn.color_palette('Set2').as_hex()[1],linewidth=3)\n",
    "    plt.plot(cum_C, label='L2/3_C', drawstyle='steps-post',color=sn.color_palette('Set2').as_hex()[2],linewidth=3)\n",
    "\n",
    "    plt.xlabel('Shuffled')\n",
    "    plt.ylabel('Cumulative Count')\n",
    "    plt.title('Random Sequence of A,B,C')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Function to calculate the binned PDF for a category\n",
    "def binned_pdf_category(category, data, bin_size=50):\n",
    "    # Total number of items in the category\n",
    "    total_count = np.sum(data == category)\n",
    "    \n",
    "    # Length of the data\n",
    "    n = len(data)\n",
    "    \n",
    "    # Number of full bins\n",
    "    num_bins = n // bin_size\n",
    "    \n",
    "    # Initialize the PDF array\n",
    "    pdf = np.zeros(num_bins)\n",
    "    \n",
    "    for i in range(num_bins):\n",
    "        bin_start = i * bin_size\n",
    "        bin_end = bin_start + bin_size\n",
    "        bin_count = np.sum(data[bin_start:bin_end] == category)\n",
    "        pdf[i] = bin_count / total_count\n",
    "    \n",
    "    return pdf\n",
    "\n",
    "def pdf_category(data,component, pc_vals,bin_size=50, ylab='Cells', title=''):\n",
    "    # Calculate the binned PDF for each category\n",
    "    binned_pdf_A = binned_pdf_category('L2/3_A', data,bin_size)\n",
    "    binned_pdf_B = binned_pdf_category('L2/3_B', data,bin_size)\n",
    "    binned_pdf_C = binned_pdf_category('L2/3_C', data, bin_size)\n",
    "\n",
    "    num_bins = len(binned_pdf_A)\n",
    "    #x_values = (np.arange(0, num_bins) + 0.5) * bin_size / len(data)\n",
    "    \n",
    "    x_values_frac = (np.arange(0, num_bins) + 0.5) * bin_size / len(data)\n",
    "\n",
    "    x_values = []\n",
    "    for i in x_values_frac:\n",
    "        x_values.append(pc_vals[int(len(pc_vals)*i)])\n",
    "\n",
    "    # Plot the binned PDF for each category\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    plt.plot(x_values, binned_pdf_A, label='A',drawstyle='steps-mid', alpha=1, color=sn.color_palette('Set2').as_hex()[0], linewidth=2)\n",
    "    plt.plot(x_values, binned_pdf_B, label='B',drawstyle='steps-mid', alpha=1,color=sn.color_palette('Set2').as_hex()[1], linewidth=2)\n",
    "    plt.plot(x_values, binned_pdf_C, label='C',drawstyle='steps-mid', alpha=1, color=sn.color_palette('Set2').as_hex()[2], linewidth=2)\n",
    "\n",
    "    # Add labels, title, and legend\n",
    "    plt.xlabel('PC'+str(component+1)+ ' Value')\n",
    "    plt.ylabel('Fraction of '+ylab)\n",
    "    plt.title(title)\n",
    "    plt.legend(bbox_to_anchor=(1,1))\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5,
     28,
     35
    ]
   },
   "outputs": [],
   "source": [
    "def cumulative_fraction_index(category, data):\n",
    "    cum_count = np.cumsum(data == category)\n",
    "    cum_fraction = cum_count / np.arange(1, len(data) + 1)\n",
    "    return cum_fraction\n",
    "\n",
    "def cum_frac_index(data,component):\n",
    "\n",
    "\n",
    "    # Cumulative fractions for each category\n",
    "    cum_frac_A = cumulative_fraction_index('L2/3_A', data)\n",
    "    cum_frac_B = cumulative_fraction_index('L2/3_B', data)\n",
    "    cum_frac_C = cumulative_fraction_index('L2/3_C', data)\n",
    "\n",
    "    # Plot cumulative fractions\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    plt.plot(cum_frac_A, label='L2/3_A', drawstyle='steps-post', color=sn.color_palette('Set2').as_hex()[0], linewidth=3)\n",
    "    plt.plot(cum_frac_B, label='L2/3_B', drawstyle='steps-post',color= sn.color_palette('Set2').as_hex()[1],linewidth=3)\n",
    "    plt.plot(cum_frac_C, label='L2/3_C', drawstyle='steps-post',color=sn.color_palette('Set2').as_hex()[2],linewidth=3)\n",
    "\n",
    "\n",
    "    plt.xlabel('Position Along PC'+str(component+1))\n",
    "    plt.ylabel('Cumulative Fraction (idx)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def cumulative_fraction_size(category, data):\n",
    "\n",
    "    cum_count = np.cumsum(data == category)\n",
    "    total_count = np.sum(data == category)\n",
    "    cum_fraction = cum_count / total_count\n",
    "    return cum_fraction\n",
    "\n",
    "def cum_frac_size(data,component):\n",
    "\n",
    "\n",
    "    # Cumulative fractions for each category\n",
    "    cum_frac_A = cumulative_fraction_size('L2/3_A', data)\n",
    "    cum_frac_B = cumulative_fraction_size('L2/3_B', data)\n",
    "    cum_frac_C = cumulative_fraction_size('L2/3_C', data)\n",
    "\n",
    "    # Plot cumulative fractions\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    plt.plot(cum_frac_A, label='L2/3_A', drawstyle='steps-post', color=sn.color_palette('Set2').as_hex()[0], linewidth=3)\n",
    "    plt.plot(cum_frac_B, label='L2/3_B', drawstyle='steps-post',color= sn.color_palette('Set2').as_hex()[1],linewidth=3)\n",
    "    plt.plot(cum_frac_C, label='L2/3_C', drawstyle='steps-post',color=sn.color_palette('Set2').as_hex()[2],linewidth=3)\n",
    "\n",
    "\n",
    "    plt.xlabel('Position Along PC'+str(component+1))\n",
    "    plt.ylabel('Cumulative Fraction (size)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def cumulative_count(data,component):\n",
    "    \n",
    "    cum_A = np.cumsum(data == 'L2/3_A')\n",
    "    cum_B = np.cumsum(data == 'L2/3_B')\n",
    "    cum_C = np.cumsum(data == 'L2/3_C')\n",
    "\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    plt.plot(cum_A, label='L2/3_A', drawstyle='steps-post', color=sn.color_palette('Set2').as_hex()[0], linewidth=3)\n",
    "    plt.plot(cum_B, label='L2/3_B', drawstyle='steps-post',color= sn.color_palette('Set2').as_hex()[1],linewidth=3)\n",
    "    plt.plot(cum_C, label='L2/3_C', drawstyle='steps-post',color=sn.color_palette('Set2').as_hex()[2],linewidth=3)\n",
    "\n",
    "    plt.xlabel('Position Along PC'+str(component+1))\n",
    "    plt.ylabel('Cumulative Count')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def runs_chi(categories):\n",
    "    import numpy as np\n",
    "    import scipy.stats as stats\n",
    "    from statsmodels.sandbox.stats.runs import runstest_1samp\n",
    "\n",
    "    # Runs Test\n",
    "\n",
    "\n",
    "    category_mapping = {'L2/3_A': 0, 'L2/3_B': 1, 'L2/3_C': 2}\n",
    "    numerical_categories = pd.Series(categories).map(category_mapping).values\n",
    "\n",
    "    # Runs Test\n",
    "    _, p_value_runs = runstest_1samp(numerical_categories, correction=False)\n",
    "    print(f'Runs Test p-value: {p_value_runs}')\n",
    "\n",
    "\n",
    "    # Chi-Square Test\n",
    "    # Dividing the list into 10 segments\n",
    "    segments = np.array_split(categories, 50)\n",
    "\n",
    "    # Counting occurrences in each segment\n",
    "    observed_counts = np.array([[np.sum(segment == 'L2/3_A'),\n",
    "                                 np.sum(segment == 'L2/3_B'),\n",
    "                                 np.sum(segment == 'L2/3_C')] for segment in segments])\n",
    "\n",
    "    # Expected counts assuming uniform distribution\n",
    "    expected_counts = np.full((10, 3), len(categories) / 30)\n",
    "\n",
    "    # Chi-square test\n",
    "    chi2, p_value_chi2, _, _ = stats.chi2_contingency(observed_counts)\n",
    "    print(f'Chi-Square Test p-value: {p_value_chi2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def pca_heatmap(adata, component, use_raw=None, layer=None, groupby='Type', frac_top=0.33):\n",
    "    attr = 'varm'\n",
    "    keys = 'PCs'\n",
    "    scores = getattr(adata, attr)[keys][:, component]\n",
    "    dd = pd.DataFrame(scores, index=adata.var_names)\n",
    "    var_names_pos = dd.sort_values(0, ascending=False).index[:20]\n",
    "\n",
    "    var_names_neg = dd.sort_values(0, ascending=True).index[:20]\n",
    "\n",
    "    pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index)\n",
    "\n",
    "    bottom_cells = pd2.sort_values(0).index[:int(frac_top*adata.shape[0])].tolist()\n",
    "    top_cells = pd2.sort_values(0, ascending=False).index[:int(frac_top*adata.shape[0])].tolist()\n",
    "    adat_use = adata[top_cells+bottom_cells]\n",
    "    \n",
    "    adat_use.obs['PC'+str(component+1)+' Score'] = list(itertools.chain.from_iterable(pd2.sort_values(0, ascending=False).values[:int(frac_top*adata.shape[0])].tolist()))+list(itertools.chain.from_iterable(pd2.sort_values(0).values[:int(frac_top*adata.shape[0])].tolist()))\n",
    "    \n",
    "    sc.pp.scale(adat_use)\n",
    "    sc.pl.heatmap(adat_use, list(var_names_pos) + list(var_names_neg), \n",
    "                        show_gene_labels=True,\n",
    "                        swap_axes=True, cmap='coolwarm', \n",
    "                        use_raw=False,vmin=-2,vmax=2, layer=layer, figsize=(3,8), \n",
    "                  groupby='PC'+str(component+1)+' Score', num_categories=1)\n",
    "    annot_bar(adat_use, groupby)\n",
    "    #print(len(bottom_cells), len(top_cells))\n",
    "    del adata.raw\n",
    "    del adat_use.raw\n",
    "    adata.obs[groupby+'_plot'] = adata.shape[0]*['All Grey']\n",
    "    adata.obs['PC'+str(component+1)+' Score'] = adata.shape[0]*[0]\n",
    "    \n",
    "    adat_use.obs[groupby+'_plot'] = adat_use.obs[groupby]\n",
    "    adata_plot = adata.concatenate(adat_use, batch_categories=['Grey', 'Colored'])\n",
    "    \n",
    "    \n",
    "    #adata.obs['PC '+str(component+1)] = adata.obsm['X_pca'][:, component]\n",
    "    \n",
    "    \n",
    "    #print(pd2.sort_values(0).values[:int(frac_top*adata.shape[0])])\n",
    "    adata_plot\n",
    "    sc.pl.umap(adata_plot, color=['PC'+str(component+1)+' Score', groupby+'_plot'],\n",
    "               s=30,#components=['1,2','2,3'],\n",
    "              cmap='coolwarm', palette=sn.color_palette('Set2').as_hex()[0:3], sort_order=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def autocorr(categories, component, shuffle=False):\n",
    "    # Function to create binary sequence for a category\n",
    "    def binary_sequence(data, category):\n",
    "        return np.array([1 if item == category else 0 for item in data])\n",
    "\n",
    "    # Function to compute autocorrelation\n",
    "    def autocorrelation(sequence):\n",
    "        n = len(sequence)\n",
    "        mean = np.mean(sequence)\n",
    "        var = np.var(sequence)\n",
    "        autocorr = np.correlate(sequence - mean, sequence - mean, mode='full') / (var * n)\n",
    "        return autocorr[n-1:]\n",
    "\n",
    "    # Binary sequences for each category\n",
    "    binary_A = binary_sequence(categories, 'L2/3_A')\n",
    "    binary_B = binary_sequence(categories, 'L2/3_B')\n",
    "    binary_C = binary_sequence(categories, 'L2/3_C')\n",
    "\n",
    "    # Compute autocorrelation for each binary sequence\n",
    "    autocorr_A = autocorrelation(binary_A)\n",
    "    autocorr_B = autocorrelation(binary_B)\n",
    "    autocorr_C = autocorrelation(binary_C)\n",
    "\n",
    "    # Plot autocorrelation\n",
    "    lags = np.arange(len(autocorr_A))\n",
    "\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    plt.plot(lags, autocorr_A, label='L2/3_A',color=sn.color_palette('Set2').as_hex()[0],)\n",
    "    plt.plot(lags, autocorr_B, label='L2/3_B',color=sn.color_palette('Set2').as_hex()[1],)\n",
    "    plt.plot(lags, autocorr_C, label='L2/3_C',color=sn.color_palette('Set2').as_hex()[2])\n",
    "\n",
    "    #plt.xlabel('Lag')\n",
    "    plt.ylabel('Autocorrelation')\n",
    "    \n",
    "    if (not shuffle): \n",
    "        plt.xlabel('Lag along PC'+str(component+1))\n",
    "    if (shuffle):\n",
    "        plt.xlabel('Shuffled Sequence')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_hmap(adata, genes, groupby,\n",
    "             show_gene_labels=True, num_categories=1, layer=None, figsize=(3,8)):\n",
    "\n",
    "\n",
    "    categories = []\n",
    "    \n",
    "    genes_loop = genes\n",
    "    genes = []\n",
    "    for i in genes_loop:\n",
    "        \n",
    "        if ('-' not in i):\n",
    "            genes.append(i)\n",
    "        \n",
    "        if (i in L23_P22_marks[0].index): categories.append('A')\n",
    "        elif (i in L23_P22_marks[1].index or i =='Baz1a'): categories.append('B')\n",
    "        elif (i in L23_P22_marks[2].index): categories.append('C')\n",
    "    \n",
    "    print(len(genes), len(categories))\n",
    "    # Create a DataFrame for gene categories\n",
    "    gene_category_df = pd.DataFrame({\n",
    "        'gene': genes,\n",
    "        'Type': categories\n",
    "    })\n",
    "\n",
    "    # Set the gene names as the index\n",
    "    gene_category_df.set_index('gene', inplace=True)\n",
    "\n",
    "    # Create a custom colormap for the categories\n",
    "    category_colors = {\n",
    "        'A': sn.color_palette('Set2').as_hex()[0],\n",
    "        'B': sn.color_palette('Set2').as_hex()[1],\n",
    "        'C': sn.color_palette('Set2').as_hex()[2]\n",
    "    }\n",
    "\n",
    "    # Plot the heatmap\n",
    "    a = sc.pl.heatmap(\n",
    "        adata,\n",
    "        var_names=genes,\n",
    "        groupby=groupby,\n",
    "        swap_axes=True,\n",
    "        cmap='coolwarm',\n",
    "        vmax=2,\n",
    "        vmin=-2,show_gene_labels=show_gene_labels, num_categories=1,\n",
    "                        use_raw=False, layer=layer, figsize=(3,8),\n",
    "        show=False,)['heatmap_ax']\n",
    "\n",
    "    # Set the y-tick labels with colors\n",
    "    y_labels = a.get_yticklabels()\n",
    "\n",
    "    for label in y_labels:\n",
    "        gene = label.get_text()\n",
    "        if gene in gene_category_df.index:\n",
    "            category = gene_category_df.loc[gene, 'Type']\n",
    "            label.set_color(category_colors[category])\n",
    "\n",
    "    # Set the y-tick labels to be italic\n",
    "    a.set_yticklabels(labels=genes, fontstyle='italic')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def pca_heatmap_all_genes_OLD(adata, component, use_raw=None, layer=None, groupby='Type'):\n",
    "    #all cells, top X genes\n",
    "    attr = 'varm'\n",
    "    if (groupby!='Type'):keys = 'PCs_rot'\n",
    "    else: keys = 'PCs'\n",
    "    scores = getattr(adata, attr)[keys][:, component]\n",
    "    dd = pd.DataFrame(scores, index=adata.var_names)\n",
    "    var_names_pos = dd.sort_values(0, ascending=False).index\n",
    "    median = int(adata.shape[1]/2)\n",
    "    \n",
    "    #print(median)\n",
    "    #var_names_mid = dd.sort_values(0, ascending=False).index[median-10:median+10]\n",
    "    #print(var_names_mid)\n",
    "    \n",
    "    var_names_neg = dd.sort_values(0, ascending=True).index\n",
    "\n",
    "    pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index)\n",
    "\n",
    "    top_cells = pd2.sort_values(0, ascending=False).index.tolist()\n",
    "    adat_use = adata[top_cells,:]\n",
    "    \n",
    "    adat_use.obs['PC'+str(component+1)+' Score'] = list(itertools.chain.from_iterable(pd2.sort_values(0, ascending=False).values.tolist()))#+list(itertools.chain.from_iterable(pd2.sort_values(0).values[:int(frac_top*adata.shape[0])].tolist()))\n",
    "    \n",
    "    sc.pp.scale(adat_use)\n",
    "#     sc.pl.heatmap(adat_use, list(var_names_pos) + list(var_names_neg), \n",
    "#                         show_gene_labels=True, num_categories=1,\n",
    "#                         swap_axes=True, cmap='coolwarm', \n",
    "#                         use_raw=False,vmin=-2,vmax=2, layer=layer, figsize=(3,8), #var_group_positions=((0,20), (20,40), (40,60)),var_group_labels=['Top', 'Middle', 'Bottom'],\n",
    "#                   groupby='PC'+str(component+1)+' Score',)\n",
    "\n",
    "    make_hmap(adata=adat_use, genes=list(var_names_pos), \n",
    "              groupby='PC'+str(component+1)+' Score', show_gene_labels=False)\n",
    "    \n",
    "    annot_bar_var(gene_list=list(var_names_pos))\n",
    "    \n",
    "    \n",
    "    annot_bar(adat_use, groupby)\n",
    "    #print(len(bottom_cells), len(top_cells))\n",
    "    cumulative_count(np.array(adat_use.obs[groupby]), component)\n",
    "    cum_frac_size(np.array(adat_use.obs[groupby]), component)\n",
    "    cum_frac_index(np.array(adat_use.obs[groupby]), component)\n",
    "    \n",
    "    pdf_category(np.array(adat_use.obs[groupby]), component)\n",
    "    \n",
    "    autocorr(np.array(adat_use.obs[groupby]), component)\n",
    "    runs_chi(np.array(adat_use.obs[groupby]))\n",
    "    sc.pl.pca(adat_use, color=['PC'+str(component+1)+' Score', groupby],legend_loc='on data',legend_fontoutline=3,\n",
    "               s=30,#components=['1,2','2,3'],\n",
    "              cmap='coolwarm', vmin=-10, vmax=10,palette=sn.color_palette('Set2').as_hex()[0:3], sort_order=True)\n",
    "    print('--------------------------------------------------------')\n",
    "    #return np.array(adat_use.obs[groupby])\n",
    "    #return dd.sort_values(0, ascending=False).index[:50], dd.sort_values(0, ascending=True).index[:50]\n",
    "    return adat_use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def pca_heatmap_all(adata, component, use_raw=None, layer=None, groupby='Type'):\n",
    "    #all cells, top X genes\n",
    "    attr = 'varm'\n",
    "    if (groupby!='Type'):keys = 'PCs_rot'\n",
    "    else: keys = 'PCs'\n",
    "    scores = getattr(adata, attr)[keys][:, component]\n",
    "    dd = pd.DataFrame(scores, index=adata.var_names)\n",
    "    var_names_pos = dd.sort_values(0, ascending=False).index[:20]\n",
    "    median = int(adata.shape[1]/2)\n",
    "    \n",
    "    #print(median)\n",
    "    #var_names_mid = dd.sort_values(0, ascending=False).index[median-10:median+10]\n",
    "    #print(var_names_mid)\n",
    "    \n",
    "    var_names_neg = dd.sort_values(0, ascending=True).index[:20]\n",
    "\n",
    "    pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index)\n",
    "\n",
    "    top_cells = pd2.sort_values(0, ascending=False).index.tolist()\n",
    "    adat_use = adata[top_cells,:]\n",
    "    \n",
    "    adat_use.obs['PC'+str(component+1)+' Score'] = list(itertools.chain.from_iterable(pd2.sort_values(0, ascending=False).values.tolist()))#+list(itertools.chain.from_iterable(pd2.sort_values(0).values[:int(frac_top*adata.shape[0])].tolist()))\n",
    "    \n",
    "    sc.pp.scale(adat_use)\n",
    "#     sc.pl.heatmap(adat_use, list(var_names_pos) + list(var_names_neg), \n",
    "#                         show_gene_labels=True, num_categories=1,\n",
    "#                         swap_axes=True, cmap='coolwarm', \n",
    "#                         use_raw=False,vmin=-2,vmax=2, layer=layer, figsize=(3,8), #var_group_positions=((0,20), (20,40), (40,60)),var_group_labels=['Top', 'Middle', 'Bottom'],\n",
    "#                   groupby='PC'+str(component+1)+' Score',)\n",
    "\n",
    "    make_hmap(adata=adat_use, genes=list(var_names_pos) + list(var_names_neg), \n",
    "              groupby='PC'+str(component+1)+' Score')\n",
    "    \n",
    "    \n",
    "    annot_bar(adat_use, groupby)\n",
    "    #print(len(bottom_cells), len(top_cells))\n",
    "    cumulative_count(np.array(adat_use.obs[groupby]), component)\n",
    "    \n",
    "    autocorr(np.array(adat_use.obs[groupby]), component)\n",
    "    runs_chi(np.array(adat_use.obs[groupby]))\n",
    "    sc.pl.umap(adat_use, color=['PC'+str(component+1)+' Score', groupby],legend_loc='on data',legend_fontoutline=3,\n",
    "               s=30,#components=['1,2','2,3'],\n",
    "              cmap='coolwarm', vmin=-10, vmax=10,palette=sn.color_palette('Set2').as_hex()[0:3], sort_order=True)\n",
    "    print('--------------------------------------------------------')\n",
    "    #return np.array(adat_use.obs[groupby])\n",
    "    return dd.sort_values(0, ascending=False).index[:50], dd.sort_values(0, ascending=True).index[:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def pca_heatmap_marks(adata, component, use_raw=None, layer=None, groupby='Type'):\n",
    "    attr = 'varm'\n",
    "    if (groupby!='Type'):keys = 'PCs_rot'\n",
    "    else: keys = 'PCs'\n",
    "    print(keys)\n",
    "    scores = getattr(adata, attr)[keys][:, component]\n",
    "    dd = pd.DataFrame(scores, index=adata.var_names)\n",
    "    var_names_pos = dd.sort_values(0, ascending=False).index[:20]\n",
    "    median = int(adata.shape[1]/2)\n",
    "    \n",
    "    #print(median)\n",
    "    var_names_mid = dd.sort_values(0, ascending=False).index[median-10:median+10]\n",
    "    #print(var_names_mid)\n",
    "    \n",
    "    var_names_neg = dd.sort_values(0, ascending=True).index[:20]\n",
    "\n",
    "    pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index)\n",
    "\n",
    "    top_cells = pd2.sort_values(0, ascending=True).index.tolist()\n",
    "    adat_use = adata[top_cells,:]\n",
    "    \n",
    "    adat_use.obs['PC'+str(component+1)+' Score'] = list(itertools.chain.from_iterable(pd2.sort_values(0, ascending=True).values.tolist()))#+list(itertools.chain.from_iterable(pd2.sort_values(0).values[:int(frac_top*adata.shape[0])].tolist()))\n",
    "    \n",
    "    sc.pp.scale(adat_use)\n",
    "    sc.pl.heatmap(adat_use, var_names=list(L23_P22_marks[0].index)+list(L23_P22_marks[1].index) + list(L23_P22_marks[2].index), \n",
    "                        show_gene_labels=False, num_categories=1,\n",
    "                        swap_axes=True, cmap='coolwarm', \n",
    "                        use_raw=False,vmin=-2,vmax=2, layer=layer, figsize=(3,8), #var_group_positions=((0,183), (183,236), (236,501)),var_group_labels=['A', 'B', 'C'],\n",
    "                  groupby='PC'+str(component+1)+' Score',)\n",
    "    annot_bar(adat_use, groupby)\n",
    "    #print(len(bottom_cells), len(top_cells))\n",
    "    cumulative_count(np.array(adat_use.obs[groupby]), component)\n",
    "    pdf_category(np.array(adat_use.obs[groupby]), component, pc_vals=adat_use.obs['PC'+str(component+1)+' Score'].values)\n",
    "\n",
    "    \n",
    "    autocorr(np.array(adat_use.obs[groupby]), component)\n",
    "    runs_chi(np.array(adat_use.obs[groupby]))\n",
    "    sc.pl.umap(adat_use, color=['PC'+str(component+1)+' Score', groupby],legend_loc='on data',legend_fontoutline=3,\n",
    "               s=30,#components=['1,2','2,3'],\n",
    "              cmap='coolwarm', vmin=-10, vmax=10,palette=sn.color_palette('Set2').as_hex()[0:3], sort_order=True)\n",
    "    print('--------------------------------------------------------')\n",
    "    return np.array(adat_use.obs[groupby])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def pca_heatmap_all_genes(adata, component, use_raw=None, layer=None, groupby='Type'):\n",
    "    #all cells, top X genes\n",
    "    attr = 'varm'\n",
    "    if (groupby!='Type'):keys = 'PCs_rot'\n",
    "    else: keys = 'PCs'\n",
    "    scores = getattr(adata, attr)[keys][:, component]\n",
    "    dd = pd.DataFrame(scores, index=adata.var_names)\n",
    "    var_names_pos = dd.sort_values(0, ascending=False).index\n",
    "    median = int(adata.shape[1]/2)\n",
    "    \n",
    "    #print(median)\n",
    "    #var_names_mid = dd.sort_values(0, ascending=False).index[median-10:median+10]\n",
    "    #print(var_names_mid)\n",
    "    \n",
    "    var_names_neg = dd.sort_values(0, ascending=True).index\n",
    "\n",
    "    pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index)\n",
    "\n",
    "    top_cells = pd2.sort_values(0, ascending=True).index.tolist()\n",
    "    adat_use = adata[top_cells,:]\n",
    "    \n",
    "    adat_use.obs['PC'+str(component+1)+' Score'] = list(itertools.chain.from_iterable(pd2.sort_values(0, ascending=True).values.tolist()))#+list(itertools.chain.from_iterable(pd2.sort_values(0).values[:int(frac_top*adata.shape[0])].tolist()))\n",
    "    \n",
    "    sc.pp.scale(adat_use)\n",
    "#     sc.pl.heatmap(adat_use, list(var_names_pos) + list(var_names_neg), \n",
    "#                         show_gene_labels=True, num_categories=1,\n",
    "#                         swap_axes=True, cmap='coolwarm', \n",
    "#                         use_raw=False,vmin=-2,vmax=2, layer=layer, figsize=(3,8), #var_group_positions=((0,20), (20,40), (40,60)),var_group_labels=['Top', 'Middle', 'Bottom'],\n",
    "#                   groupby='PC'+str(component+1)+' Score',)\n",
    "\n",
    "    make_hmap(adata=adat_use, genes=list(var_names_pos), \n",
    "              groupby='PC'+str(component+1)+' Score', show_gene_labels=False)\n",
    "    \n",
    "    annot_bar_var(gene_list=list(var_names_pos))\n",
    "    \n",
    "    \n",
    "    annot_bar(adat_use, groupby)\n",
    "    #print(len(bottom_cells), len(top_cells))\n",
    "    cumulative_count(np.array(adat_use.obs[groupby]), component)\n",
    "    cum_frac_size(np.array(adat_use.obs[groupby]), component)\n",
    "    cum_frac_index(np.array(adat_use.obs[groupby]), component)\n",
    "    \n",
    "    pdf_category(np.array(adat_use.obs[groupby]), component, pc_vals=adat_use.obs['PC'+str(component+1)+' Score'].values)\n",
    "    \n",
    "    autocorr(np.array(adat_use.obs[groupby]), component)\n",
    "    runs_chi(np.array(adat_use.obs[groupby]))\n",
    "    sc.pl.pca(adat_use, color=['PC'+str(component+1)+' Score', groupby],legend_loc='on data',legend_fontoutline=3,\n",
    "               s=30,#components=['1,2','2,3'],\n",
    "              cmap='coolwarm', vmin=-10, vmax=10,palette=sn.color_palette('Set2').as_hex()[0:3], sort_order=True)\n",
    "    print('--------------------------------------------------------')\n",
    "    #return np.array(adat_use.obs[groupby])\n",
    "    #return dd.sort_values(0, ascending=False).index[:50], dd.sort_values(0, ascending=True).index[:50]\n",
    "    return adat_use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_P22_marks[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "236+265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_FF.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def pca_heatmap_marks(adata, component, use_raw=None, layer=None, groupby='Type'):\n",
    "    attr = 'varm'\n",
    "    if (groupby!='Type'):keys = 'PCs_rot'\n",
    "    else: keys = 'PCs'\n",
    "    print(keys)\n",
    "    scores = getattr(adata, attr)[keys][:, component]\n",
    "    dd = pd.DataFrame(scores, index=adata.var_names)\n",
    "    var_names_pos = dd.sort_values(0, ascending=False).index[:20]\n",
    "    median = int(adata.shape[1]/2)\n",
    "    \n",
    "    #print(median)\n",
    "    var_names_mid = dd.sort_values(0, ascending=False).index[median-10:median+10]\n",
    "    #print(var_names_mid)\n",
    "    \n",
    "    var_names_neg = dd.sort_values(0, ascending=True).index[:20]\n",
    "\n",
    "    pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index)\n",
    "\n",
    "    top_cells = pd2.sort_values(0, ascending=False).index.tolist()\n",
    "    adat_use = adata[top_cells,:]\n",
    "    \n",
    "    adat_use.obs['PC'+str(component+1)+' Score'] = list(itertools.chain.from_iterable(pd2.sort_values(0, ascending=False).values.tolist()))#+list(itertools.chain.from_iterable(pd2.sort_values(0).values[:int(frac_top*adata.shape[0])].tolist()))\n",
    "    \n",
    "    sc.pp.scale(adat_use)\n",
    "    sc.pl.heatmap(adat_use, var_names=list(L23_P22_marks[0].index)+list(L23_P22_marks[1].index) + list(L23_P22_marks[2].index), \n",
    "                        show_gene_labels=False, num_categories=1,\n",
    "                        swap_axes=True, cmap='coolwarm', \n",
    "                        use_raw=False,vmin=-2,vmax=2, layer=layer, figsize=(3,12), #var_group_positions=((0,183), (183,236), (236,501)),var_group_labels=['A', 'B', 'C'],\n",
    "                  groupby='PC'+str(component+1)+' Score',)\n",
    "    annot_bar(adat_use, groupby)\n",
    "    #print(len(bottom_cells), len(top_cells))\n",
    "    cumulative_count(np.array(adat_use.obs[groupby]), component)\n",
    "    \n",
    "    autocorr(np.array(adat_use.obs[groupby]), component)\n",
    "    runs_chi(np.array(adat_use.obs[groupby]))\n",
    "    sc.pl.umap(adat_use, color=['PC'+str(component+1)+' Score', groupby],legend_loc='on data',legend_fontoutline=3,\n",
    "               s=30,#components=['1,2','2,3'],\n",
    "              cmap='coolwarm', vmin=-10, vmax=10,palette=sn.color_palette('Set2').as_hex()[0:3], sort_order=True)\n",
    "    print('--------------------------------------------------------')\n",
    "    return np.array(adat_use.obs[groupby])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorr(np.array(shuffle(L23_FF.obs['P22 Mapping Label'])), component=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorr(np.array(shuffle(L23_P22.obs['Type'])), component=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_count_shuff(np.array(shuffle(L23_FF.obs['P22 Mapping Label'])))  # Replace with your list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_count_shuff(np.array(shuffle(L23_P22.obs['Type'])))  # Replace with your list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_chi(np.array(shuffle(L23_FF.obs['P22 Mapping Label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Cdh12' in L23_P22_marks[2].index[0:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Cdh12' in L23_FF.var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_heatmap_all_genes(L23_FF, 0, groupby='P22 Mapping Label')\n",
    "pca_heatmap_all_genes(L23_FF, 1, groupby='P22 Mapping Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_heatmap_all_genes(L23_P22, 0, groupby='Type')\n",
    "pca_heatmap_all_genes(L23_P22, 1, groupby='Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "pca_heatmap_marks(L23_FF, 0, groupby='P22 Mapping Label')\n",
    "pca_heatmap_marks(L23_FF, 1, groupby='P22 Mapping Label')\n",
    "pca_heatmap_marks(L23_FF, 2, groupby='P22 Mapping Label')\n",
    "pca_heatmap_marks(L23_FF, 3, groupby='P22 Mapping Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_labs = []\n",
    "for i in L23_FF.var_names:\n",
    "    if (i in L23_P22_marks[0].index): mark_labs.append('L2/3_A')\n",
    "    elif (i in L23_P22_marks[1].index): mark_labs.append('L2/3_B')\n",
    "    elif (i in L23_P22_marks[2].index): mark_labs.append('L2/3_C')\n",
    "    else:\n",
    "        print(i)\n",
    "        mark_labs.append('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(L23_FF.var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mark_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_FF.var['Type'] = mark_labs\n",
    "L23_P22.var['Type'] = mark_labs\n",
    "\n",
    "L23_FF.var['PC1 P12'] = L23_FF.varm['PCs_rot'][:,0]\n",
    "L23_FF.var['PC1 P22'] = L23_P22.varm['PCs'][:,0]\n",
    "\n",
    "L23_FF.var['PC2 P12'] = L23_FF.varm['PCs_rot'][:,1]\n",
    "L23_FF.var['PC2 P22'] = L23_P22.varm['PCs'][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.distplot(L23_FF.var[L23_FF.var['Type']=='L2/3_B']['PC1 P12'])\n",
    "sn.distplot(L23_FF.var[L23_FF.var['Type']=='L2/3_B']['PC1 P22'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_category_genes(data,component, ylim, bin_size=50, ylab='Cells', title=''):\n",
    "    # Calculate the binned PDF for each category\n",
    "    binned_pdf_A = binned_pdf_category('L2/3_A', data,bin_size)\n",
    "    binned_pdf_B = binned_pdf_category('L2/3_B', data,bin_size)\n",
    "    binned_pdf_C = binned_pdf_category('L2/3_C', data, bin_size)\n",
    "\n",
    "    num_bins = len(binned_pdf_A)\n",
    "    x_values = (np.arange(0, num_bins) + 0.5) * bin_size / len(data)\n",
    "\n",
    "    \n",
    "    # Plot the binned PDF for each category\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    plt.plot(x_values, binned_pdf_A, label='A',drawstyle='steps-mid', alpha=1, color=sn.color_palette('Set2').as_hex()[0], linewidth=2)\n",
    "    plt.plot(x_values, binned_pdf_B, label='B',drawstyle='steps-mid', alpha=1,color=sn.color_palette('Set2').as_hex()[1], linewidth=2)\n",
    "    plt.plot(x_values, binned_pdf_C, label='C',drawstyle='steps-mid', alpha=1, color=sn.color_palette('Set2').as_hex()[2], linewidth=2)\n",
    "\n",
    "    # Add labels, title, and legend\n",
    "    plt.xlabel('Fractional Position Along PC'+str(component+1))\n",
    "    plt.ylabel('Fraction of '+ylab)\n",
    "    plt.title(title)\n",
    "    plt.ylim(ylim)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "    return binned_pdf_A,binned_pdf_B,binned_pdf_C\n",
    "\n",
    "def diff(first, second, title):\n",
    "    \n",
    "    A = np.abs(first[0]-second[0])\n",
    "    B = np.abs(first[1]-second[1])  \n",
    "    C = np.abs(first[2]-second[2]) \n",
    "\n",
    "    plt.figure(figsize=(4,2))\n",
    "    plt.plot(np.arange(len(A))/len(A), A, label='A', color=sn.color_palette('Set2').as_hex()[0])\n",
    "    plt.plot(np.arange(len(A))/len(A), B, label='B',color=sn.color_palette('Set2').as_hex()[1])\n",
    "    plt.plot(np.arange(len(A))/len(A), C, label='C',color=sn.color_palette('Set2').as_hex()[2])\n",
    "\n",
    "    plt.xlabel('Position Along PC1')\n",
    "    plt.ylabel('Absolute Difference')\n",
    "    plt.grid(False)\n",
    "    plt.title(title)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FF_PC1 = pdf_category_genes(np.array(L23_FF.var.sort_values(by='PC1 P12', ascending=True)['Type']), \n",
    "             component=0,bin_size=10, ylab='Genes', title='P22 10d-WD', ylim=[0,0.2])\n",
    "P22_PC1 = pdf_category_genes(np.array(L23_FF.var.sort_values(by='PC1 P22', ascending=True)['Type']), \n",
    "                             component=0,bin_size=10,\n",
    "             ylab='Genes', title='P22', ylim=[0,0.2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FF_PC2 = pdf_category_genes(np.array(L23_FF.var.sort_values(by='PC2 P12', ascending=True)['Type']), component=1,\n",
    "                            bin_size=10,\n",
    "            ylab='Genes', title='P22 10d-WD',ylim=[0,0.22])\n",
    "P22_PC2 = pdf_category_genes(np.array(L23_FF.var.sort_values(by='PC2 P22', ascending=True)['Type']), component=1,bin_size=10,\n",
    "            ylab='Genes', title='P22',ylim=[0,0.22])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "def jj(first, second, title):\n",
    "    \n",
    "    A = jensenshannon(first[0], second[0])**2\n",
    "    B = jensenshannon(first[1], second[1])**2  # The function returns the square root of JS divergence\n",
    "    C = jensenshannon(first[2], second[2])**2  # The function returns the square root of JS divergence\n",
    "\n",
    "    plt.figure(figsize=(2.5,3))\n",
    "    plt.bar(['A','B','C'], [A,B,C], color='#D294E5', edgecolor='black')\n",
    "    plt.xlabel('L2/3 Type')\n",
    "    plt.ylabel('Jenson-Shannon Divergence')\n",
    "    plt.grid(False)\n",
    "    plt.title(title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jj(FF_PC1, P22_PC1, 'PC1')\n",
    "diff(FF_PC1, P22_PC1, 'PC1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jj(FF_PC2, P22_PC2, 'PC2')\n",
    "diff(FF_PC2, P22_PC2, 'PC2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.scatterplot(data=L23_FF.var, x='PC1 P12', y='PC1 P22', hue='Type')\n",
    "plt.xlim([-0.17,0.17])\n",
    "plt.ylim([-0.17,0.17])\n",
    "plt.plot(np.linspace(-0.2,0.2,10),np.linspace(-0.2,0.2,10), color='black')\n",
    "plt.show()\n",
    "\n",
    "sn.scatterplot(data=L23_FF.var, x='PC2 P12', y='PC2 P22', hue='Type')\n",
    "plt.xlim([-0.17,0.17])\n",
    "plt.ylim([-0.17,0.17])\n",
    "plt.plot(np.linspace(-0.2,0.2,10),np.linspace(-0.2,0.2,10), color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_colors = {\n",
    "    'Category1': 'blue',\n",
    "    'Category2': 'green',\n",
    "    'Category3': 'red'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p12_pc1p, p12_pc1n = pca_heatmap_all(L23_FF, 0, groupby='P22 Mapping Label')\n",
    "p12_pc2p, p12_pc2n = pca_heatmap_all(L23_FF, 1, groupby='P22 Mapping Label')\n",
    "# pca_heatmap_all(L23_FF, 2, groupby='P22 Mapping Label')\n",
    "# pca_heatmap_all(L23_FF, 3, groupby='P22 Mapping Label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_chi(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_heatmap(L23_FF, 0, groupby='P22 Mapping Label', frac_top=0.2)\n",
    "pca_heatmap(L23_FF, 1,groupby='P22 Mapping Label',frac_top=0.2)\n",
    "pca_heatmap(L23_FF, 2,groupby='P22 Mapping Label',frac_top=0.2)\n",
    "pca_heatmap(L23_FF, 3,groupby='P22 Mapping Label',frac_top=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_heatmap_raw(L23_FF, 0, groupby='P22 Mapping Label', frac_top=0.33)\n",
    "pca_heatmap_raw(L23_FF, 1,groupby='P22 Mapping Label',frac_top=0.33)\n",
    "pca_heatmap_raw(L23_FF, 2,groupby='P22 Mapping Label',frac_top=0.33)\n",
    "pca_heatmap_raw(L23_FF, 3,groupby='P22 Mapping Label',frac_top=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(L23_FF, color=['P22 Mapping Label'],title='P12 Cells: P22 Mapping Label', \n",
    "               s=30,palette=sn.color_palette('Set2').as_hex()[0:3])\n",
    "sc.pl.umap(L23_P22, color=['Type'],title='P22 Cells: Type', \n",
    "               s=30,palette=sn.color_palette('Set2').as_hex()[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_heatmap(L23_FF, 0,)\n",
    "pca_heatmap(L23_FF, 1)\n",
    "pca_heatmap(L23_FF, 2)\n",
    "pca_heatmap(L23_FF, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.pca(L23_FF, color=['P22 Mapping Label','P22 Mapping Prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_heatmap_marks(L23_P22, 0)\n",
    "pca_heatmap_marks(L23_P22, 1)\n",
    "pca_heatmap_marks(L23_P22, 2)\n",
    "pca_heatmap_marks(L23_P22, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_P22_marks[0].shape, L23_P22_marks[1].shape, L23_P22_marks[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings1 = L23_FF.varm['PCs_rot'][:,0][:183]  # Loadings for PC1 in dataset1\n",
    "loadings2 = L23_P22.varm['PCs'][:,0][:183]  # Loadings for PC1 in dataset2\n",
    "\n",
    "# Create a DataFrame to compare loadings\n",
    "features = L23_P22.var_names[:183]  # List of feature names\n",
    "comparison_df = pd.DataFrame({\n",
    "    'gene': features,\n",
    "    'P22 10d-WD': loadings1,\n",
    "    'P22': loadings2,\n",
    "    'P22 - P12': loadings2 - loadings1,\n",
    "    'P22 / P12': loadings2 / (loadings1+0.01)\n",
    "})\n",
    "\n",
    "# Visualize the loadings\n",
    "plt.figure(figsize=(50, 6))\n",
    "comparison_df.plot(x='gene', y='P22 - P12', kind='bar', ax=plt.gca())\n",
    "plt.title('Comparison of PC1 Loadings')\n",
    "plt.ylabel('Loading Ratio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install POT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings1 = L23_FF.varm['PCs_rot'][:,0]  # Loadings for PC1 in dataset1\n",
    "loadings2 = L23_P22.varm['PCs'][:,0]  # Loadings for PC1 in dataset2\n",
    "\n",
    "# Create a DataFrame to compare loadings\n",
    "features = L23_P22.var_names  # List of feature names\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Loadings_Dataset1': loadings1,\n",
    "    'Loadings_Dataset2': loadings2,\n",
    "    'Difference': loadings1 - loadings2,\n",
    "    'Ratio': loadings1 / loadings2\n",
    "})\n",
    "\n",
    "# Visualize the loadings\n",
    "plt.figure(figsize=(50, 6))\n",
    "comparison_df.plot(x='Feature', y='Ratio', kind='bar', ax=plt.gca())\n",
    "plt.title('Comparison of PC1 Loadings')\n",
    "plt.ylabel('Loading Value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p22pc1p , p22pc1n = pca_heatmap_all(L23_P22, 0)\n",
    "p22pc2p , p22pc2n = pca_heatmap_all(L23_P22, 1)\n",
    "# pca_heatmap_all(L23_P22, 2)\n",
    "# pca_heatmap_all(L23_P22, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def jaccard_index(list1, list2):\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    \n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    \n",
    "    if not union:\n",
    "        return 0.0\n",
    "    \n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "# Example usage:\n",
    "list1 = [1, 2, 3, 4]\n",
    "list2 = [3, 4, 5, 6]\n",
    "\n",
    "print(jaccard_index(list1, list2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "jaccard_index(p12_pc1p, p22pc1p), jaccard_index(p12_pc2p, p22pc2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_index(p12_pc1n, p22pc1n), jaccard_index(p12_pc2n, p22pc2n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_heatmap(L23_P22, 0,frac_top=0.2)\n",
    "pca_heatmap(L23_P22, 1,frac_top=0.2)\n",
    "pca_heatmap(L23_P22, 2,frac_top=0.2)\n",
    "pca_heatmap(L23_P22, 3,frac_top=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_heatmap_raw(L23_P22, 0, groupby='Type', frac_top=0.33)\n",
    "pca_heatmap_raw(L23_P22, 1,groupby='Type',frac_top=0.33)\n",
    "pca_heatmap_raw(L23_P22, 2,groupby='Type',frac_top=0.33)\n",
    "pca_heatmap_raw(L23_P22, 3,groupby='Type',frac_top=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2 = pd.DataFrame(L23_FF.obsm['X_pca'][:, 0], index=L23_FF.obs.index)\n",
    "top_cells_12 = pd2.sort_values(0, ascending=False).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd2 = pd.DataFrame(L23_P22.obsm['X_pca'][:, 0], index=L23_P22.obs.index)\n",
    "top_cells_22 = pd2.sort_values(0, ascending=False).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd2.sort_values(0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23.obs.index = L23.obs.index.str.replace('-P12','')\n",
    "L23.obs.index = L23.obs.index.str.replace('-P22','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_ord = L23[top_cells_12+top_cells_22,:].copy()\n",
    "L23_ord.obs['Order'] = np.arange(L23_ord.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_ord.obs['Order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.heatmap(L23_ord, var_names=list(L23_P22_marks[0].index)+list(L23_P22_marks[1].index)+list(L23_P22_marks[2].index), \n",
    "              groupby='Type_Age', \n",
    "              swap_axes=True,use_raw=False, vmin=-2, vmax=2, cmap='coolwarm', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample markers Fig 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = L23_P22.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_P22.X, L23_FF.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ABC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plt_score_idx(datasets, genes, title_colors, component=0, bin_size=75, nrows=1, ncols=1):\n",
    "    # Create a figure with the specified number of rows and columns for subplots\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(4 * ncols, 2.5 * nrows), sharey=False, sharex=True)\n",
    "    \n",
    "    # Flatten axes array for easy iteration if it's multi-dimensional\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    c = 0\n",
    "    for ax, gene in zip(axes, genes):\n",
    "        for adata, age, color in datasets:\n",
    "            pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index)\n",
    "            top_cells = pd2.sort_values(0, ascending=True).index.tolist()\n",
    "            adat_use = adata[top_cells, :]\n",
    "\n",
    "            positions = np.arange(adat_use.shape[0])\n",
    "            expression_values  = adat_use.obs[gene].values\n",
    "            \n",
    "            # Number of full bins\n",
    "            num_bins = len(positions) // bin_size\n",
    "\n",
    "            # Initialize arrays to store binned positions and expression values\n",
    "            binned_positions = np.zeros(num_bins)\n",
    "            binned_expression = np.zeros(num_bins)\n",
    "\n",
    "            for i in range(num_bins):\n",
    "                bin_start = i * bin_size\n",
    "                bin_end = bin_start + bin_size\n",
    "                binned_positions[i] = (bin_start + bin_end) / 2  # Middle of the bin\n",
    "                binned_expression[i] = np.mean(expression_values[bin_start:bin_end])\n",
    "\n",
    "            # Normalize the x-axis values to range from 0 to 1\n",
    "            normalized_positions = binned_positions / len(positions)\n",
    "                \n",
    "\n",
    "            # Plot the binned gene expression values\n",
    "            ax.plot(normalized_positions, binned_expression, drawstyle='steps-mid', linewidth=2, label=age, color=color)\n",
    "\n",
    "        # Add labels, title, and legend for each subplot\n",
    "        ax.set_title(gene, color=title_colors[c], style='italic')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        c += 1\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for i in range(len(genes), len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp, ks_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_1samp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def plt_score_idx_with_ttest(datasets, genes, title_colors, save, component=0, bin_size=75, nrows=1, ncols=1):\n",
    "    # Create a figure with the specified number of rows and columns for subplots\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(4 * ncols, 2.5 * nrows), sharey=False, sharex=True)\n",
    "    \n",
    "    # Flatten axes array for easy iteration if it's multi-dimensional\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    c = 0\n",
    "    for ax, gene in zip(axes, genes):\n",
    "        binned_expressions = []\n",
    "        for adata, age, color in datasets:\n",
    "            pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index)\n",
    "            top_cells = pd2.sort_values(0, ascending=True).index.tolist()\n",
    "            adat_use = adata[top_cells, :]\n",
    "\n",
    "            positions = np.arange(adat_use.shape[0])\n",
    "            expression_values  = adat_use.obs[gene].values\n",
    "            \n",
    "            \n",
    "            # Number of full bins\n",
    "            num_bins = len(positions) // bin_size\n",
    "\n",
    "            # Initialize arrays to store binned positions and expression values\n",
    "            binned_positions = np.zeros(num_bins)\n",
    "            binned_expression = np.zeros(num_bins)\n",
    "\n",
    "            for i in range(num_bins):\n",
    "                bin_start = i * bin_size\n",
    "                bin_end = bin_start + bin_size\n",
    "                binned_positions[i] = (bin_start + bin_end) / 2  # Middle of the bin\n",
    "                binned_expression[i] = np.mean(expression_values[bin_start:bin_end])\n",
    "\n",
    "            # Normalize the x-axis values to range from 0 to 1\n",
    "            normalized_positions = binned_positions / len(positions)\n",
    "            \n",
    "            # Plot the binned gene expression values\n",
    "            ax.plot(normalized_positions, binned_expression, drawstyle='steps-mid', linewidth=2, label=age, color=color)\n",
    "                    \n",
    "            # Collect binned expressions for t-test\n",
    "            binned_expressions.append(binned_expression)\n",
    "\n",
    "        # Perform t-test between the two sets of binned expressions\n",
    "        if len(binned_expressions) == 2:\n",
    "            t_stat, p_val = ks_2samp(binned_expressions[0], binned_expressions[1],)\n",
    "            # Include p-value in the title\n",
    "            ax.set_title(f'{gene}\\n(p = {p_val:.2e})', color=title_colors[c], style='italic')\n",
    "        else:\n",
    "            ax.set_title(gene, color=title_colors[c], style='italic')\n",
    "\n",
    "        # Add labels, title, and legend for each subplot\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        c += 1\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for i in range(len(genes), len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show plot\n",
    "    plt.savefig(save)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plt_gene_idx(datasets, genes, title_colors, save, component=0, bin_size=75, nrows=1, ncols=1):\n",
    "    # Create a figure with the specified number of rows and columns for subplots\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(4 * ncols, 2.7 * nrows), sharey=False)\n",
    "    \n",
    "    # Flatten axes array for easy iteration if it's multi-dimensional\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    c = 0\n",
    "    for ax, gene in zip(axes, genes):\n",
    "        binned_expressions = []\n",
    "        for adata, age, color in datasets:\n",
    "            pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index)\n",
    "            top_cells = pd2.sort_values(0, ascending=True).index.tolist()\n",
    "            adat_use = adata[top_cells, :]\n",
    "\n",
    "            positions = np.arange(adat_use.shape[0])\n",
    "            expression_values = adat_use.X[:, adat_use.var_names.get_loc(gene)].A  # values\n",
    "\n",
    "            # Number of full bins\n",
    "            num_bins = len(positions) // bin_size\n",
    "\n",
    "            # Initialize arrays to store binned positions and expression values\n",
    "            binned_positions = np.zeros(num_bins)\n",
    "            binned_expression = np.zeros(num_bins)\n",
    "\n",
    "            for i in range(num_bins):\n",
    "                bin_start = i * bin_size\n",
    "                bin_end = bin_start + bin_size\n",
    "                binned_positions[i] = (bin_start + bin_end) / 2  # Middle of the bin\n",
    "                binned_expression[i] = np.mean(expression_values[bin_start:bin_end])\n",
    "\n",
    "            # Normalize the x-axis values to range from 0 to 1\n",
    "            normalized_positions = binned_positions / len(positions)\n",
    "\n",
    "            # Plot the binned gene expression values\n",
    "            ax.plot(normalized_positions, binned_expression, drawstyle='steps-mid', linewidth=2, label=age, color=color)\n",
    "            \n",
    "            # Collect binned expressions for t-test\n",
    "            binned_expressions.append(binned_expression)\n",
    "            #print(len(binned_positions), len(binned_expression))\n",
    "\n",
    "         # Perform t-test between the two sets of binned expressions\n",
    "#         if len(binned_expressions) == 2:\n",
    "#             t_stat, p_val = ttest_ind(binned_expressions[0], binned_expressions[1], equal_var=False)\n",
    "#             # Include p-value in the title\n",
    "#             gene_bold_italic = f'\\\\textbf{{\\\\textit{{{gene}}}}}'\n",
    "#             ax.set_title(f'{gene_bold_italic}\\n(p = {p_val:.2e})', color=title_colors[c], style='italic', usetex=True)\n",
    "#             #ax.set_title(f'{gene}\\n(p = {p_val:.2e})', color=title_colors[c], style='italic')\n",
    "#         else:\n",
    "#             ax.set_title(gene, color=title_colors[c], style='italic', fontweight='bold')\n",
    "\n",
    "        # Add labels, title, and legend for each subplot\n",
    "        ax.set_title(gene, color=title_colors[c], style='italic', fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        c += 1\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for i in range(len(genes), len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Show plot\n",
    "    plt.savefig(save)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_FF.X = L23_FF.raw.X\n",
    "L23_P22.X = L23_P22.raw.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "datasets = [\n",
    "    (L23_FF, 'P22 10d AWD', '#e78ac3'),\n",
    "    (L23_P22, 'P22', '#a6d854')\n",
    "]\n",
    "\n",
    "genes = ['A Score', 'B Score', 'C Score']  # Add your genes here\n",
    "\n",
    "plt_score_idx_with_ttest(datasets, genes, title_colors=sn.color_palette('Set2').as_hex()[0:3], nrows=3, ncols=1,\n",
    "                        save='figures/FigS8A.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-ran the PCA on Type markers 6.1 section, adding Baz1a to marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "datasets = [\n",
    "    (L23_FF, 'P22 10d AWD', '#e78ac3'),\n",
    "    (L23_P22, 'P22', '#a6d854')\n",
    "]\n",
    "\n",
    "genes = ['Cdh13', 'Trpc6', 'Chrm2'] +['Adamts2', 'Bdnf', 'Cdh12']+ ['Sorcs3', 'Igfn1','Baz1a',] \n",
    "\n",
    "plt_gene_idx(datasets, genes, title_colors=sn.color_palette('Set2').as_hex()[0:3]+sn.color_palette('Set2').as_hex()[0:3]+len(genes)*[sn.color_palette('Set2').as_hex()[1]], \n",
    "             nrows=3, ncols=3, save='figures/Fig6F.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "datasets = [\n",
    "    (L23_FF, 'P22 10d-WD', '#e78ac3'),\n",
    "    (L23_P22, 'P22', '#a6d854')\n",
    "]\n",
    "\n",
    "genes = ['Cdh13', 'Trpc6', 'Chrm2'] +['Adamts2', 'Bdnf', 'Cdh12']+ ['Sorcs3', 'Igfn1','Baz1a',] \n",
    "\n",
    "plt_gene_idx(datasets, genes, title_colors=sn.color_palette('Set2').as_hex()[0:3]+sn.color_palette('Set2').as_hex()[0:3]+len(genes)*[sn.color_palette('Set2').as_hex()[1]], \n",
    "             nrows=3, ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L23_FF.obs.Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "datasets = [\n",
    "    (L23_FF, 'P22 10d-WD', '#e78ac3'),\n",
    "    (L23_P22, 'P22', '#a6d854')\n",
    "]\n",
    "\n",
    "genes = list(L23_P22_marks[0].index[0:30]) +list(L23_P22_marks[1].index[0:30])+ list(L23_P22_marks[2].index[0:30])\n",
    "\n",
    "plt_gene_idx(datasets, genes, title_colors=30*[sn.color_palette('Set2').as_hex()[0]]+30*[sn.color_palette('Set2').as_hex()[1]]+30*[sn.color_palette('Set2').as_hex()[2]], \n",
    "             nrows=10, ncols=9, bin_size=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "path_dbs = 'Final_Gene_Lists/'\n",
    "csms = list(pd.read_csv(path_dbs+'csm_final.csv')['gene'])\n",
    "ics = list(pd.read_csv(path_dbs+'ion_final.csv')['gene'])\n",
    "nps = list(pd.read_csv(path_dbs+'Neuropeptides.csv', header=None, names=['Genes'])['Genes'])\n",
    "ntr = list(pd.read_csv(path_dbs+'ntr_final.csv')['gene'])\n",
    "gpcrs = list(pd.read_excel('MouseHumanRatGPCRs.xlsx')['Gene Symbol (Mouse)'].values)\n",
    "\n",
    "L23_genes = pd.read_excel('L23_56.xlsx', index_col=0)\n",
    "L23_genes = list(L23_genes.index)+['Tnc']\n",
    "\n",
    "tfs = pd.read_table('TFs_mm.txt', header=0)\n",
    "tfs = list(tfs['Bcl6b'].values)+['Bcl6b']\n",
    "\n",
    "house = list(pd.read_table('Bulk Cluster Ubiquitous.txt',).transpose()[0:3000].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Cpne8' in csms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    (L23_FF, 'P22 10d-WD', '#e78ac3'),\n",
    "    (L23_P22, 'P22', '#a6d854')\n",
    "]\n",
    "\n",
    "genes = list(set(L23_P22_marks[0].index).intersection(set(tfs)))  # Add your genes here\n",
    "\n",
    "plt_gene_idx(datasets, genes,title_colors=len(genes)*[sn.color_palette('Set2').as_hex()[0]], \n",
    "             nrows=4, ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    (L23_FF, 'P22 10d-WD', '#e78ac3'),\n",
    "    (L23_P22, 'P22', '#a6d854')\n",
    "]\n",
    "\n",
    "genes = list(set(L23_P22_marks[1].index).intersection(set(tfs)))  # Add your genes here\n",
    "\n",
    "plt_gene_idx(datasets, genes, title_colors=len(genes)*[sn.color_palette('Set2').as_hex()[1]],ncols=2, nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "datasets = [\n",
    "    (L23_FF, 'P22 10d-WD', '#e78ac3'),\n",
    "    (L23_P22, 'P22', '#a6d854')\n",
    "]\n",
    "\n",
    "genes = list(set(L23_P22_marks[2].index).intersection(set(tfs)))  # Add your genes here\n",
    "\n",
    "plt_gene_idx(datasets, genes, title_colors=len(genes)*[sn.color_palette('Set2').as_hex()[2]],nrows=7, ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dbs = 'Final_Gene_Lists/'\n",
    "\n",
    "ics = list(pd.read_csv(path_dbs+'ion_final.csv')['gene'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    (L23_FF, 'P22 10d-WD', '#e78ac3'),\n",
    "    (L23_P22, 'P22', '#a6d854')\n",
    "]\n",
    "\n",
    "genes = list(set(L23_P22_marks[0].index).intersection(set(ics)))  # Add your genes here\n",
    "\n",
    "plt_gene_idx(datasets, genes, title_colors=len(genes)*[sn.color_palette('Set2').as_hex()[0]],nrows=2, ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    (L23_FF, 'P22 10d-WD', '#e78ac3'),\n",
    "    (L23_P22, 'P22', '#a6d854')\n",
    "]\n",
    "\n",
    "genes = list(set(L23_P22_marks[1].index).intersection(set(ics)))  # Add your genes here\n",
    "\n",
    "plt_gene_idx(datasets, genes, title_colors=len(genes)*[sn.color_palette('Set2').as_hex()[1]],ncols=1, nrows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    (L23_FF, 'P22 10d-WD', '#e78ac3'),\n",
    "    (L23_P22, 'P22', '#a6d854')\n",
    "]\n",
    "\n",
    "genes = list(set(L23_P22_marks[2].index).intersection(set(ics)))  # Add your genes here\n",
    "\n",
    "plt_gene_idx(datasets, genes, title_colors=len(genes)*[sn.color_palette('Set2').as_hex()[2]],nrows=3, ncols=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (xgb_env)",
   "language": "python",
   "name": "xgb_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "380.469px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
